{"cells":[{"cell_type":"markdown","metadata":{"id":"aFvq0jAA-9Ho"},"source":["## All imports"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"HyO794DUJnU8","executionInfo":{"status":"ok","timestamp":1675094259988,"user_tz":-60,"elapsed":28665,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["#from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertModel\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","#from transformers import BertTokenizer,BertModel\n","from sklearn.metrics import confusion_matrix\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","#from transformers import BertConfig\n","from torch.autograd import Variable\n","#from transformers import logging\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","import torch.utils.data as data\n","import torch.optim as optim\n","from pprint import pprint\n","#from torchcrf import CRF\n","import matplotlib as mp\n","import torch.nn as nn\n","from tqdm import tqdm\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","import sklearn\n","import random\n","import torch\n","import json\n","import os\n","\n","import random\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","import torch\n","import os\n","import json\n","from pprint import pprint\n","import torch.optim as optim\n","import sklearn\n","import matplotlib as mp\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","import spacy\n","import en_core_web_sm\n","#spacy_nlp = spacy.load(\"en-core-web-sm\")\n","\n","nlp = en_core_web_sm.load()\n","# Global variables\n","device = 'cuda:0' if torch.cuda.is_available() else 'cpu' # cuda:0 means we are using the GPU with id 0, if you have multiple GPU\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" # Used to report errors on CUDA side\n","PAD_TOKEN = 0"]},{"cell_type":"markdown","metadata":{"id":"H0JN6bwYjcSe"},"source":["## Importing DATABASE"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1442,"status":"ok","timestamp":1675094261424,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"},"user_tz":-60},"id":"T6dfh4WwKMqJ","outputId":"58f1cf23-3da3-480b-a4a1-1e3ea87f5c4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'IntentSlotDatasets'...\n","remote: Enumerating objects: 40, done.\u001b[K\n","remote: Counting objects: 100% (40/40), done.\u001b[K\n","remote: Compressing objects: 100% (29/29), done.\u001b[K\n","remote: Total 40 (delta 9), reused 25 (delta 6), pack-reused 0\u001b[K\n","Unpacking objects: 100% (40/40), 1.05 MiB | 4.23 MiB/s, done.\n"]}],"source":["!git clone https://github.com/BrownFortress/IntentSlotDatasets"]},{"cell_type":"markdown","metadata":{"id":"jRpFeQSAiWa9"},"source":["## Functions in cnll.py file"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"mXw0rlbdddT4","executionInfo":{"status":"ok","timestamp":1675094261425,"user_tz":-60,"elapsed":36,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["import re\n","\n","\"\"\"\n","Modified version of https://pypi.org/project/conlleval/\n","\"\"\"\n","\n","\n","def stats():\n","    return {'cor': 0, 'hyp': 0, 'ref': 0}\n","\n","\n","def evaluate(ref, hyp, otag='O'):\n","    # evaluation for NLTK\n","    aligned = align_hyp(ref, hyp)\n","    return conlleval(aligned, otag=otag)\n","\n","\n","def align_hyp(ref, hyp):\n","    # align references and hypotheses for evaluation\n","    # add last element of token tuple in hyp to ref\n","    if len(ref) != len(hyp):\n","        raise ValueError(\"Size Mismatch: ref: {} & hyp: {}\".format(len(ref), len(hyp)))\n","\n","    out = []\n","    for i in range(len(ref)):\n","        if len(ref[i]) != len(hyp[i]):\n","            raise ValueError(\"Size Mismatch: ref: {} & hyp: {}\".format(len(ref), len(hyp)))\n","        out.append([(*ref[i][j], hyp[i][j][-1]) for j in range(len(ref[i]))])\n","    return out\n","\n","\n","def conlleval(data, otag='O'):\n","    # token, segment & class level counts for TP, TP+FP, TP+FN\n","    tok = stats()\n","    seg = stats()\n","    cls = {}\n","\n","    for sent in data:\n","\n","        prev_ref = otag      # previous reference label\n","        prev_hyp = otag      # previous hypothesis label\n","        prev_ref_iob = None  # previous reference label IOB\n","        prev_hyp_iob = None  # previous hypothesis label IOB\n","\n","        in_correct = False  # currently processed chunks is correct until now\n","\n","        for token in sent:\n","\n","            hyp_iob, hyp = parse_iob(token[-1])\n","            ref_iob, ref = parse_iob(token[-2])\n","\n","            ref_e = is_eoc(ref, ref_iob, prev_ref, prev_ref_iob, otag)\n","            hyp_e = is_eoc(hyp, hyp_iob, prev_hyp, prev_hyp_iob, otag)\n","\n","            ref_b = is_boc(ref, ref_iob, prev_ref, prev_ref_iob, otag)\n","            hyp_b = is_boc(hyp, hyp_iob, prev_hyp, prev_hyp_iob, otag)\n","\n","            if not cls.get(ref) and ref:\n","                cls[ref] = stats()\n","\n","            if not cls.get(hyp) and hyp:\n","                cls[hyp] = stats()\n","\n","            # segment-level counts\n","            if in_correct:\n","                if ref_e and hyp_e and prev_hyp == prev_ref:\n","                    in_correct = False\n","                    seg['cor'] += 1\n","                    cls[prev_ref]['cor'] += 1\n","\n","                elif ref_e != hyp_e or hyp != ref:\n","                    in_correct = False\n","\n","            if ref_b and hyp_b and hyp == ref:\n","                in_correct = True\n","\n","            if ref_b:\n","                seg['ref'] += 1\n","                cls[ref]['ref'] += 1\n","\n","            if hyp_b:\n","                seg['hyp'] += 1\n","                cls[hyp]['hyp'] += 1\n","\n","            # token-level counts\n","            if ref == hyp and ref_iob == hyp_iob:\n","                tok['cor'] += 1\n","\n","            tok['ref'] += 1\n","\n","            prev_ref = ref\n","            prev_hyp = hyp\n","            prev_ref_iob = ref_iob\n","            prev_hyp_iob = hyp_iob\n","\n","        if in_correct:\n","            seg['cor'] += 1\n","            cls[prev_ref]['cor'] += 1\n","\n","    return summarize(seg, cls)\n","\n","\n","def parse_iob(t):\n","    m = re.match(r'^([^-]*)-(.*)$', t)\n","    return m.groups() if m else (t, None)\n","\n","\n","def is_boc(lbl, iob, prev_lbl, prev_iob, otag='O'):\n","    \"\"\"\n","    is beginning of a chunk\n","\n","    supports: IOB, IOBE, BILOU schemes\n","        - {E,L} --> last\n","        - {S,U} --> unit\n","\n","    :param lbl: current label\n","    :param iob: current iob\n","    :param prev_lbl: previous label\n","    :param prev_iob: previous iob\n","    :param otag: out-of-chunk label\n","    :return:\n","    \"\"\"\n","    boc = False\n","\n","    boc = True if iob in ['B', 'S', 'U'] else boc\n","    boc = True if iob in ['E', 'L'] and prev_iob in ['E', 'L', 'S', otag] else boc\n","    boc = True if iob == 'I' and prev_iob in ['S', 'L', 'E', otag] else boc\n","\n","    boc = True if lbl != prev_lbl and iob != otag and iob != '.' else boc\n","\n","    # these chunks are assumed to have length 1\n","    boc = True if iob in ['[', ']'] else boc\n","\n","    return boc\n","\n","\n","def is_eoc(lbl, iob, prev_lbl, prev_iob, otag='O'):\n","    \"\"\"\n","    is end of a chunk\n","\n","    supports: IOB, IOBE, BILOU schemes\n","        - {E,L} --> last\n","        - {S,U} --> unit\n","\n","    :param lbl: current label\n","    :param iob: current iob\n","    :param prev_lbl: previous label\n","    :param prev_iob: previous iob\n","    :param otag: out-of-chunk label\n","    :return:\n","    \"\"\"\n","    eoc = False\n","\n","    eoc = True if iob in ['E', 'L', 'S', 'U'] else eoc\n","    eoc = True if iob == 'B' and prev_iob in ['B', 'I'] else eoc\n","    eoc = True if iob in ['S', 'U'] and prev_iob in ['B', 'I'] else eoc\n","\n","    eoc = True if iob == otag and prev_iob in ['B', 'I'] else eoc\n","\n","    eoc = True if lbl != prev_lbl and iob != otag and prev_iob != '.' else eoc\n","\n","    # these chunks are assumed to have length 1\n","    eoc = True if iob in ['[', ']'] else eoc\n","\n","    return eoc\n","\n","\n","def score(cor_cnt, hyp_cnt, ref_cnt):\n","    # precision\n","    p = 1 if hyp_cnt == 0 else cor_cnt / hyp_cnt\n","    # recall\n","    r = 0 if ref_cnt == 0 else cor_cnt / ref_cnt\n","    # f-measure (f1)\n","    f = 0 if p+r == 0 else (2*p*r)/(p+r)\n","    return {\"precision\": p, \"recall\": r, \"f-measure\": f, \"support\": ref_cnt}\n","\n","\n","def summarize(seg, cls):\n","    # class-level\n","    res = {lbl: score(cls[lbl]['cor'], cls[lbl]['hyp'], cls[lbl]['ref']) for lbl in set(cls.keys())}\n","    # micro\n","    res.update({\"total\": score(seg.get('cor', 0), seg.get('hyp', 0), seg.get('ref', 0))})\n","    return res\n","\n","\n","def read_corpus_conll(corpus_file, fs=\"\\t\"):\n","    \"\"\"\n","    read corpus in CoNLL format\n","    :param corpus_file: corpus in conll format\n","    :param fs: field separator\n","    :return: corpus\n","    \"\"\"\n","    featn = None  # number of features for consistency check\n","    sents = []  # list to hold words list sequences\n","    words = []  # list to hold feature tuples\n","\n","    for line in open(corpus_file):\n","        line = line.strip()\n","        if len(line.strip()) > 0:\n","            feats = tuple(line.strip().split(fs))\n","            if not featn:\n","                featn = len(feats)\n","            elif featn != len(feats) and len(feats) != 0:\n","                raise ValueError(\"Unexpected number of columns {} ({})\".format(len(feats), featn))\n","\n","            words.append(feats)\n","        else:\n","            if len(words) > 0:\n","                sents.append(words)\n","                words = []\n","    return sents\n","\n","\n","def get_chunks(corpus_file, fs=\"\\t\", otag=\"O\"):\n","    sents = read_corpus_conll(corpus_file, fs=fs)\n","    return set([parse_iob(token[-1])[1] for sent in sents for token in sent if token[-1] != otag])"]},{"cell_type":"markdown","metadata":{"id":"EWeBWpJXi771"},"source":["# Data Utils"]},{"cell_type":"markdown","metadata":{"id":"5etZmGJn0aXP"},"source":["The function then loads the train and test datasets for two different datasets, 'ATIS' and 'SNIPS', and prints the number of samples in each dataset. \n","It also prints a random sample of 5 items from each dataset by using random.sample function."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1675094261425,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"},"user_tz":-60},"id":"fUzz8JyNKB_c","outputId":"69cb55e8-5a3d-42b5-9f01-f801f5a55e71"},"outputs":[{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","Train samples: 4978\n","Test samples: 893\n","=========================================================================================\n","Train samples: 13084\n","Test samples: 700\n","Dev samples: 700\n","=========================================================================================\n","{'intent': 'ground_service',\n"," 'slots': 'O B-city_name I-city_name O O O O O O B-transport_type',\n"," 'utterance': \"in new york i 'll need to rent a car\"}\n","{'intent': 'flight',\n"," 'slots': 'O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name',\n"," 'utterance': 'show me the flights from denver to westchester county'}\n","{'intent': 'flight',\n"," 'slots': 'O O O O O B-fromloc.city_name O B-toloc.city_name O '\n","          'B-depart_date.month_name B-depart_date.day_number '\n","          'B-depart_time.time I-depart_time.time',\n"," 'utterance': 'what flights are available from boston to atlanta on july '\n","              'seventh 8 am'}\n","{'intent': 'flight',\n"," 'slots': 'O O O O B-toloc.city_name I-toloc.city_name O B-fromloc.city_name O '\n","          'O B-stoploc.city_name',\n"," 'utterance': 'show me flights to san francisco from philadelphia stopping in '\n","              'dallas'}\n","{'intent': 'flight',\n"," 'slots': 'O O O O O B-fromloc.city_name O O B-depart_time.period_of_day O '\n","          'B-depart_date.day_name O O O B-toloc.city_name I-toloc.city_name',\n"," 'utterance': 'now i need flights leaving denver in the afternoon on wednesday '\n","              'and arriving in san francisco'}\n","=========================================================================================\n","{'intent': 'BookRestaurant',\n"," 'slots': 'O O B-party_size_number O B-restaurant_name I-restaurant_name '\n","          'I-restaurant_name O B-state',\n"," 'utterance': 'party for ten at national coney island in de'}\n","{'intent': 'AddToPlaylist',\n"," 'slots': 'O O O B-entity_name I-entity_name I-entity_name O O B-playlist '\n","          'I-playlist I-playlist',\n"," 'utterance': 'add the name the magnificent tree to playlist this is rosana'}\n","{'intent': 'GetWeather',\n"," 'slots': 'O O O O O O B-current_location',\n"," 'utterance': 'give me the weather forecast for here'}\n","{'intent': 'BookRestaurant',\n"," 'slots': 'O O O O B-party_size_number O O B-cuisine B-restaurant_type O '\n","          'B-timeRange I-timeRange O B-city B-state I-state',\n"," 'utterance': 'book a reservation for one at an italian taverna for two pm in '\n","              'hutchings  north dakota'}\n","{'intent': 'AddToPlaylist',\n"," 'slots': 'O O O B-entity_name I-entity_name I-entity_name O O '\n","          'B-playlist_owner B-playlist I-playlist O',\n"," 'utterance': 'i want some fusil contra fusil added to my dance hits playlist'}\n","=========================================================================================\n"]}],"source":["def load_data(path):\n","    '''\n","        input: path/to/data\n","        output: json \n","    '''\n","    dataset = []\n","    with open(path) as f:\n","        dataset = json.loads(f.read())\n","    return dataset\n","\n","ATIS_tmp_train_raw = load_data(os.path.join('/content/IntentSlotDatasets','ATIS','train.json'))\n","ATIS_test_raw = load_data(os.path.join('/content/IntentSlotDatasets','ATIS','test.json'))\n","print('='*89)\n","print('Train samples:', len(ATIS_tmp_train_raw))\n","print('Test samples:', len(ATIS_test_raw))\n","print('='*89)\n","\n","SNIPS_train_raw = load_data(os.path.join('/content/IntentSlotDatasets','SNIPS','train.json'))\n","SNIPS_test_raw = load_data(os.path.join('/content/IntentSlotDatasets','SNIPS','test.json'))\n","SNIPS_dev_raw = load_data(os.path.join('/content/IntentSlotDatasets','SNIPS','valid.json'))\n","print('Train samples:', len(SNIPS_train_raw))\n","print('Test samples:', len(SNIPS_test_raw))\n","print('Dev samples:', len(SNIPS_dev_raw))\n","print('='*89)\n","\n","ATIS_indices = random.sample(range(len(ATIS_tmp_train_raw)), 5)\n","SNIPS_indices = random.sample(range(len(SNIPS_train_raw)), 5)\n","\n","for index in ATIS_indices:\n","  pprint(ATIS_tmp_train_raw[index])\n","print('='*89)\n","for index in SNIPS_indices:\n","  pprint(SNIPS_train_raw[index])\n","print('='*89)"]},{"cell_type":"markdown","metadata":{"id":"KkBgsi6j00Zb"},"source":["We take a portion of the ATIS training and test data and splits it into three sets: train, dev, and test. The portion of the data that will be used for dev set is calculated by taking 10% of the total number of samples in both the train and test datasets, and then stratifying the data based on the 'intent' attribute of each sample. \n","Then we remove any intents that only appear once in the dataset, as it makes no sense to put those in the dev set. \n","Finally, we use the train_test_split function to split the data into train and dev sets, and then extends the train set with the intents that were removed earlier.And then we print the size of each dataset (train, dev, and test)."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1675094261425,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"},"user_tz":-60},"id":"osO6GWQOKDb8","outputId":"0f28739f-3f78-4d2e-dedc-38e4350352e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","TRAIN size: 4381\n","=========================================================================================\n","DEV size: 597\n","=========================================================================================\n","TEST size: 893\n","=========================================================================================\n"]}],"source":["portion = round(((len(ATIS_tmp_train_raw) + len(ATIS_test_raw)) * 0.10)/(len(ATIS_tmp_train_raw)),2)\n","\n","ATIS_intents = [x['intent'] for x in ATIS_tmp_train_raw] # We stratify on intents\n","ATIS_count_y = Counter(ATIS_intents)\n","\n","ATIS_X = []\n","ATIS_Y = []\n","ATIS_mini_Train = []\n","\n","for id_y, y in enumerate(ATIS_intents):\n","    if ATIS_count_y[y] > 1: # Some intents have only one instance, we put them in training\n","        ATIS_X.append(ATIS_tmp_train_raw[id_y])\n","        ATIS_Y.append(y)\n","    else:\n","        ATIS_mini_Train.append(ATIS_tmp_train_raw[id_y])\n","# Random Stratify\n","ATIS_X_train, ATIS_X_dev, ATIS_y_train, ATIS_y_dev = train_test_split(ATIS_X, ATIS_Y, test_size=portion, \n","                                                    random_state=42, \n","                                                    shuffle=True,\n","                                                    stratify=ATIS_Y)\n","ATIS_X_train.extend(ATIS_mini_Train)\n","ATIS_train_raw = ATIS_X_train\n","ATIS_dev_raw = ATIS_X_dev\n","\n","y_test_ATIS = [x['intent'] for x in ATIS_test_raw]\n","\n","# Dataset size\n","print('='*89)\n","print('TRAIN size:', len(ATIS_train_raw))\n","print('='*89)\n","print('DEV size:', len(ATIS_dev_raw))\n","print('='*89)\n","print('TEST size:', len(ATIS_test_raw))\n","print('='*89)"]},{"cell_type":"markdown","metadata":{"id":"Jhkenh1011Zw"},"source":["Lang function to map words, slots, intents to unique id's."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"BJReiIIzNVm1","executionInfo":{"status":"ok","timestamp":1675094261426,"user_tz":-60,"elapsed":33,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["class Lang():\n","    def __init__(self, words, intents, slots, cutoff=0):\n","        self.word2id = self.w2id(words, cutoff=cutoff, unk=True)\n","        self.slot2id = self.lab2id(slots)\n","        self.intent2id = self.lab2id(intents, pad=False)\n","        self.id2word = {v:k for k, v in self.word2id.items()}\n","        self.id2slot = {v:k for k, v in self.slot2id.items()}\n","        self.id2intent = {v:k for k, v in self.intent2id.items()}\n","        \n","    def w2id(self, elements, cutoff=None, unk=True):\n","        vocab = {'pad': PAD_TOKEN}\n","        if unk:\n","            vocab['unk'] = len(vocab)\n","        count = Counter(elements)\n","        for k, v in count.items():\n","            if v > cutoff:\n","                vocab[k] = len(vocab)\n","        return vocab\n","    \n","    def lab2id(self, elements, pad=True):\n","        vocab = {}\n","        if pad:\n","            vocab['pad'] = PAD_TOKEN\n","        for elem in elements:\n","                vocab[elem] = len(vocab)\n","        return vocab"]},{"cell_type":"markdown","metadata":{"id":"08umK_Ni2bn_"},"source":["ATIS_words: iterating through each sample in 'ATIS_train_raw' and getting the 'utterance' field, then splitting it into words.\n","\n","ATIS_corpus: concatenating the lists 'ATIS_train_raw', 'ATIS_dev_raw', and 'ATIS_test_raw'.\n","\n","ATIS_slots: iterating through each sample in 'ATIS_corpus' and getting the 'slots' field, then splitting it into slots and adding it to the set.\n","\n","ATIS_intents: iterating through each sample in 'ATIS_corpus' and getting the 'intent' field, then adding it to the set.\n","\n","ATIS_lang: instance of the Lang class by passing in the three sets created earlier and an optional 'cutoff' parameter. This will initialize the class and create the three dictionaries word2id, slot2id, and intent2id."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"qQamv5WPNWRN","executionInfo":{"status":"ok","timestamp":1675094261426,"user_tz":-60,"elapsed":31,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["# Create a list of all the words in the 'utterance' field of each sample in ATIS_train_raw\n","ATIS_words = [word for line in ATIS_train_raw for word in line['utterance'].split()]\n","\n","# Concatenate the lists ATIS_train_raw, ATIS_dev_raw, and ATIS_test_raw\n","ATIS_corpus = ATIS_train_raw + ATIS_dev_raw + ATIS_test_raw\n","\n","# Create a set of all the slot names in ATIS_corpus\n","ATIS_slots = set(slot for line in ATIS_corpus for slot in line['slots'].split())\n","\n","# Create a set of all the intent names in ATIS_corpus\n","ATIS_intents = set(line['intent'] for line in ATIS_corpus)\n","\n","# Instantiate the Lang class\n","ATIS_lang = Lang(ATIS_words, ATIS_intents, ATIS_slots, cutoff=0)\n"]},{"cell_type":"markdown","metadata":{"id":"rQFuz_OQ3xfK"},"source":["SNIPS_words: iterating through each sample in 'SNIPS_train_raw' and getting the 'utterance' field, then splitting it into words.\n","\n","SNIPS_corpus: concatenating the lists 'SNIPS_train_raw', 'SNIPS_dev_raw', and 'SNIPS_test_raw'.\n","\n","SNIPS_slots: iterating through each sample in 'SNIPS_corpus' and getting the 'slots' field, then splitting it into slots and adding it to the set.\n","\n","SNIPS_intents: iterating through each sample in 'SNIPS_corpus' and getting the 'intent' field, then adding it to the set.\n","\n","SNIPS_lang: instance of the Lang class by passing in the three sets created earlier and an optional 'cutoff' parameter. This will initialize the class and create the three dictionaries word2id, slot2id, and intent2id."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"uFS2ZPsZOjzb","executionInfo":{"status":"ok","timestamp":1675094261427,"user_tz":-60,"elapsed":31,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["# Create a list of all the words in the 'utterance' field of each sample in SNIPS_train_raw\n","SNIPS_words = [word for line in SNIPS_train_raw for word in line['utterance'].split()]\n","\n","# Concatenate the lists SNIPS_train_raw, SNIPS_dev_raw, and SNIPS_test_raw\n","SNIPS_corpus = SNIPS_train_raw + SNIPS_dev_raw + SNIPS_test_raw\n","\n","# Create a set of all the slot names in SNIPS_corpus\n","SNIPS_slots = set(slot for line in SNIPS_corpus for slot in line['slots'].split())\n","\n","# Create a set of all the intent names in SNIPS_corpus\n","SNIPS_intents = set(line['intent'] for line in SNIPS_corpus)\n","\n","# Instantiate the Lang class\n","SNIPS_lang = Lang(SNIPS_words, SNIPS_intents, SNIPS_slots, cutoff=0)\n"]},{"cell_type":"markdown","metadata":{"id":"BqHSiNB863hy"},"source":["A print of the first 5 items of each of the three dictionaries, word2id, intent2id, and slot2id, that were created when the Lang class was instantiated.  \n","The word2id dictionary maps words to unique integers, the intent2id dictionary maps intent names to unique integers, and the slot2id dictionary maps slot names to unique integers."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1675094261427,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"},"user_tz":-60},"id":"nOa7DvJ-OoL2","outputId":"c53cfa86-36f1-4678-a326-5fccc587f87d"},"outputs":[{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","[('pad', 0), ('unk', 1), ('what', 2), ('type', 3), ('of', 4)]\n","=========================================================================================\n","[('ground_service+ground_fare', 0), ('day_name', 1), ('quantity', 2), ('flight+airfare', 3), ('abbreviation', 4)]\n","=========================================================================================\n","[('pad', 0), ('B-flight_number', 1), ('I-meal_description', 2), ('B-or', 3), ('B-stoploc.airport_code', 4)]\n","=========================================================================================\n"]}],"source":["print('='*89)\n","print(list(ATIS_lang.word2id.items())[:5])\n","print('='*89)\n","print(list(ATIS_lang.intent2id.items())[:5])\n","print('='*89)\n","print(list(ATIS_lang.slot2id.items())[:5])\n","print('='*89)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1675094261427,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"},"user_tz":-60},"id":"ZtgQToeYRINv","outputId":"631809da-df3e-4ca5-b460-b45a3957628a"},"outputs":[{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","[('pad', 11250), ('unk', 1), ('listen', 2), ('to', 3), ('westbam', 4)]\n","=========================================================================================\n","[('PlayMusic', 0), ('AddToPlaylist', 1), ('RateBook', 2), ('SearchScreeningEvent', 3), ('BookRestaurant', 4)]\n","=========================================================================================\n","[('pad', 0), ('B-album', 1), ('B-music_item', 2), ('B-restaurant_name', 3), ('B-playlist_owner', 4)]\n","=========================================================================================\n"]}],"source":["print('='*89)\n","print(list(SNIPS_lang.word2id.items())[:5])\n","print('='*89)\n","print(list(SNIPS_lang.intent2id.items())[:5])\n","print('='*89)\n","print(list(SNIPS_lang.slot2id.items())[:5])\n","print('='*89)"]},{"cell_type":"markdown","metadata":{"id":"O-YoJfm-768T"},"source":["Class used to convert the data into numerical format."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"IdU_emt5SYOS","executionInfo":{"status":"ok","timestamp":1675094261428,"user_tz":-60,"elapsed":26,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["import torch\n","import torch.utils.data as data\n","\n","class IntentsAndSlots(data.Dataset):\n","    # Mandatory methods are __init__, __len__ and __getitem__\n","    def __init__(self, dataset, lang, unk='unk'):\n","        self.utterances = []\n","        self.intents = []\n","        self.slots = []\n","        self.unk = unk\n","        \n","        for x in dataset:\n","            self.utterances.append(x['utterance'])\n","            self.slots.append(x['slots'])\n","            self.intents.append(x['intent'])\n","\n","    # Convert to numbers\n","        self.utt_ids = self.mapping_seq(self.utterances, lang.word2id)\n","        self.slot_ids = self.mapping_seq(self.slots, lang.slot2id)\n","        self.intent_ids = self.mapping_lab(self.intents, lang.intent2id)\n","\n","    def __len__(self):\n","        return len(self.utterances)\n","\n","    def __getitem__(self, idx):\n","        # Get the sequence of word ids for the given index\n","        utt = torch.Tensor(self.utt_ids[idx])\n","        # Get the sequence of slot ids for the given index\n","        slots = torch.Tensor(self.slot_ids[idx])\n","        # Get the intent id for the given index\n","        intent = self.intent_ids[idx]\n","        # Return a sample with the sequence of word ids, sequence of slot ids, and intent id\n","        sample = {'utterance': utt, 'slots': slots, 'intent': intent}\n","        return sample \n","    \n","    # Auxiliary methods\n","    \n","    def mapping_lab(self, data, mapper):\n","        \"\"\"\n","        Map a list of labels to a list of integers using the given mapping.\n","        If a label is not in the mapping, it is mapped to the integer corresponding to the \"unk\" key.\n","        \"\"\"      \n","        return [mapper[x] if x in mapper else mapper[self.unk] for x in data]\n","    \n","    def mapping_seq(self, data, mapper): \n","        \"\"\"\n","        Map a list of sequences of tokens to a list of sequences of integers using the given mapping.\n","        If a token is not in the mapping, it is mapped to the integer corresponding to the \"unk\" key.\n","        \"\"\"\n","        res = []\n","        for seq in data:\n","            tmp_seq = []\n","            for x in seq.split():\n","                if x in mapper:\n","                    tmp_seq.append(mapper[x])\n","                else:\n","                    tmp_seq.append(mapper[self.unk])\n","            res.append(tmp_seq)\n","        return res\n"]},{"cell_type":"markdown","metadata":{"id":"qzZpwwZR8Q7w"},"source":["Creation of dataset objects for training, validation and test for both ATIS and SNIPS datasets."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Ygms4o7uSqGo","executionInfo":{"status":"ok","timestamp":1675094261428,"user_tz":-60,"elapsed":25,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["# Create ATIS datasets\n","\n","ATIS_train_dataset = IntentsAndSlots(ATIS_train_raw, ATIS_lang)\n","ATIS_dev_dataset = IntentsAndSlots(ATIS_dev_raw, ATIS_lang)\n","ATIS_test_dataset = IntentsAndSlots(ATIS_test_raw, ATIS_lang)\n","\n","# Create SNIPS datasets\n","\n","SNIPS_train_dataset = IntentsAndSlots(SNIPS_train_raw, SNIPS_lang)\n","SNIPS_dev_dataset = IntentsAndSlots(SNIPS_dev_raw, SNIPS_lang)\n","SNIPS_test_dataset = IntentsAndSlots(SNIPS_test_raw, SNIPS_lang)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1675094261429,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"},"user_tz":-60},"id":"put7n1ffW9m1","outputId":"bb7d57ea-a4cd-4588-9c02-da50b32cb411"},"outputs":[{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","Size of ATIS train dataset: 4381\n","Size of ATIS dev dataset: 597\n","Size of ATIS test dataset: 893\n","=========================================================================================\n","Size of SNIPS train dataset: 13084\n","Size of SNIPS dev dataset: 700\n","Size of SNIPS test dataset: 700\n","=========================================================================================\n"]}],"source":["print('='*89)\n","print(f'Size of ATIS train dataset: {len(ATIS_train_dataset)}')\n","print(f'Size of ATIS dev dataset: {len(ATIS_dev_dataset)}')\n","print(f'Size of ATIS test dataset: {len(ATIS_test_dataset)}')\n","print('='*89)\n","print(f'Size of SNIPS train dataset: {len(SNIPS_train_dataset)}')\n","print(f'Size of SNIPS dev dataset: {len(SNIPS_dev_dataset)}')\n","print(f'Size of SNIPS test dataset: {len(SNIPS_test_dataset)}')\n","print('='*89)"]},{"cell_type":"markdown","metadata":{"id":"_2b1tX2yIz1G"},"source":["A function that sorts and collates the input data into tensors ready for use in a PyTorch DataLoader. It sorts the data by the length of the 'utterance' field in descending order, creates tensors for the source utterance, intent and y_slots and the lengths of the slots and loads these tensors on the specified device.  \n","It returns a dictionary containing all the collated data."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Y8pJyn8-XUN5","executionInfo":{"status":"ok","timestamp":1675094261429,"user_tz":-60,"elapsed":23,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","def collate_fn(data):\n","    def merge(sequences):\n","        '''\n","        merge from batch * sent_len to batch * max_len \n","        '''\n","        lengths = [len(seq) for seq in sequences]\n","        max_len = 1 if max(lengths)==0 else max(lengths)\n","        # Pad token is zero in our case\n","        # So we create a matrix full of PAD_TOKEN (i.e. 0) with the shape \n","        # batch_size X maximum length of a sequence\n","        padded_seqs = torch.LongTensor(len(sequences), max_len).fill_(PAD_TOKEN)\n","        for i, seq in enumerate(sequences):\n","            end = lengths[i]\n","            padded_seqs[i, :end] = seq # We copy each sequence into the matrix\n","        # print(padded_seqs)\n","        padded_seqs = padded_seqs.detach()  # We remove these tensors from the computational graph\n","        return padded_seqs, lengths\n","        \n","    # Sort data by seq lengths\n","    data.sort(key=lambda x: len(x['utterance']), reverse=True) \n","    new_item = {}\n","    for key in data[0].keys():\n","        new_item[key] = [d[key] for d in data]\n","    # We just need one length for packed pad seq, since len(utt) == len(slots)\n","    src_utt, _ = merge(new_item['utterance'])\n","    y_slots, y_lengths = merge(new_item[\"slots\"])\n","    intent = torch.LongTensor(new_item[\"intent\"])\n","    \n","    src_utt = src_utt.to(device) # We load the Tensor on our seleceted device\n","    y_slots = y_slots.to(device)\n","    intent = intent.to(device)\n","    y_lengths = torch.LongTensor(y_lengths).to(device)\n","    \n","    new_item[\"utterances\"] = src_utt\n","    new_item[\"intents\"] = intent\n","    new_item[\"y_slots\"] = y_slots\n","    new_item[\"slots_len\"] = y_lengths\n","    return new_item"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"FOIeHV8sn64d","executionInfo":{"status":"ok","timestamp":1675094261429,"user_tz":-60,"elapsed":22,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["# ATIS Dataloaders \n","\n","ATIS_train_loader = DataLoader(ATIS_train_dataset, batch_size=128, collate_fn=collate_fn,  shuffle=True)\n","ATIS_dev_loader = DataLoader(ATIS_dev_dataset, batch_size=64, collate_fn=collate_fn)\n","ATIS_test_loader = DataLoader(ATIS_test_dataset, batch_size=64, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"VzTSUX7ioAGn","executionInfo":{"status":"ok","timestamp":1675094261430,"user_tz":-60,"elapsed":23,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["# SNIPS Dataloaders\n","\n","SNIPS_train_loader = DataLoader(SNIPS_train_dataset, batch_size=128, collate_fn=collate_fn,  shuffle=True)\n","SNIPS_dev_loader = DataLoader(SNIPS_dev_dataset, batch_size=64, collate_fn=collate_fn)\n","SNIPS_test_loader = DataLoader(SNIPS_test_dataset, batch_size=64, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1675094261430,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"},"user_tz":-60},"id":"-qFBtPMZV_D6","outputId":"fc923f45-3f35-49d7-a2a1-b17b12d01c6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","130\n","26\n","ATIS vocabulary len:  863\n","=========================================================================================\n","73\n","7\n","SNIPS vocabulary len:  11419\n","=========================================================================================\n"]}],"source":["ATIS_out_slot = len(ATIS_lang.slot2id)\n","ATIS_out_int = len(ATIS_lang.intent2id)\n","ATIS_vocab_len = len(ATIS_lang.word2id)\n","\n","SNIPS_out_slot = len(SNIPS_lang.slot2id)\n","SNIPS_out_int = len(SNIPS_lang.intent2id)\n","SNIPS_vocab_len = len(SNIPS_lang.word2id)\n","\n","print('='*89)\n","print(ATIS_out_slot)\n","print(ATIS_out_int)\n","print(\"ATIS vocabulary len: \", ATIS_vocab_len)\n","print('='*89)\n","print(SNIPS_out_slot)\n","print(SNIPS_out_int)\n","print(\"SNIPS vocabulary len: \", SNIPS_vocab_len)\n","print('='*89)"]},{"cell_type":"markdown","metadata":{"id":"Zh7hCNj0Lw33"},"source":["Function that is used to initialize the weights of the model.  \n","It initializes the weights of the GRU, LSTM, and RNN layers using the Xavier uniform initialization and the weights of the Linear layers using uniform initialization with values between -0.01 and 0.01. \n","It also fills the bias terms with 0 for all layers. This helps to improve the training and generalization performance of the model."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"bc4fHLwNorns","executionInfo":{"status":"ok","timestamp":1675094261430,"user_tz":-60,"elapsed":21,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["def init_weights(mat):\n","    for m in mat.modules():\n","        if type(m) in [nn.GRU, nn.LSTM, nn.RNN]:\n","            for name, param in m.named_parameters():\n","                if 'weight_ih' in name:\n","                    for idx in range(4):\n","                        mul = param.shape[0]//4\n","                        torch.nn.init.xavier_uniform_(param[idx*mul:(idx+1)*mul])\n","                elif 'weight_hh' in name:\n","                    for idx in range(4):\n","                        mul = param.shape[0]//4\n","                        torch.nn.init.orthogonal_(param[idx*mul:(idx+1)*mul])\n","                elif 'bias' in name:\n","                    param.data.fill_(0)\n","        else:\n","            if type(m) in [nn.Linear]:\n","                torch.nn.init.uniform_(m.weight, -0.01, 0.01)\n","                if m.bias != None:\n","                    m.bias.data.fill_(0.01)"]},{"cell_type":"markdown","metadata":{"id":"-VgknZm2Mgvh"},"source":["A function that creates two confusion matrices, one for slots and one for intents. The confusion matrices are initialized as 2D arrays with dimensions equal to the number of distinct slots or intents, respectively. The values in the matrices are filled with 0."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"qX1OkNsLoY1U","executionInfo":{"status":"ok","timestamp":1675094261431,"user_tz":-60,"elapsed":21,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["def initialize_confusion_matrices(lang):\n","  cm_slot = np.zeros((len(lang.id2slot), len(lang.id2slot)))\n","  cm_intent = np.zeros((len(lang.id2intent), len(lang.id2intent)))\n","  return cm_slot, cm_intent"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"-If5HtBsGT-T","executionInfo":{"status":"ok","timestamp":1675094261431,"user_tz":-60,"elapsed":20,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["hid_size = 200\n","emb_size = 300\n","\n","lr = 0.0001 # learning rate\n","\n","criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n","criterion_intents = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{"id":"krbPlc38ptBf"},"source":["# First Model"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"Vvm9OxNCqH4n","executionInfo":{"status":"ok","timestamp":1675090451682,"user_tz":-60,"elapsed":8,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["class ModelIAS(nn.Module):\n","\n","    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=1, pad_index=0):\n","        super(ModelIAS, self).__init__()\n","        \n","        # Initialize the embedding layer with the given vocabulary length and embedding size\n","        self.embedding = nn.Embedding(vocab_len, emb_size, padding_idx=pad_index)\n","        # Initialize the LSTM layer with the given hidden size, number of layers, and bidirectional flag\n","        self.utt_encoder = nn.LSTM(emb_size, hid_size, n_layer, bidirectional=False)    \n","        # Initialize a linear layer for producing the output for slot filling\n","        self.slot_out = nn.Linear(hid_size, out_slot)\n","        # Initialize a linear layer for producing the output for intent classification\n","        self.intent_out = nn.Linear(hid_size, out_int)\n","        \n","    def forward(self, utterance, seq_lengths):\n","        # utterance.size() = batch_size X seq_len\n","        # Convert the input utterance to embeddings\n","        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n","        # Reshape the embeddings to be of size: sequence length, batch size, embedding size\n","        utt_emb = utt_emb.permute(1,0,2) # we need seq len first -> seq_len X batch_size X emb_size\n","        \n","        # Pack the padded sequence to remove the padding\n","        packed_input = pack_padded_sequence(utt_emb, seq_lengths.cpu().numpy())\n","        # Process the batch\n","        packed_output, (last_hidden, cell) = self.utt_encoder(packed_input) \n","        # Unpack the packed sequence\n","        utt_encoded, input_sizes = pad_packed_sequence(packed_output)\n","        # Get the last hidden state of the LSTM\n","        last_hidden = last_hidden[-1,:,:]\n","        # Compute the logits for the slot filling output\n","        slots = self.slot_out(utt_encoded)\n","        # Compute the logits for the intent classification output\n","        intent = self.intent_out(last_hidden)\n","        \n","        # Slot size: seq_len, batch size, calsses \n","        # Reshape the slots tensor to be of size: batch size, classes, sequence length for computing the loss\n","        slots = slots.permute(1,2,0) # We need this for computing the loss\n","        # Slot size: batch_size, classes, seq_len\n","        # Return the slots and intent predictions\n","        return slots, intent"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"hwLsFkA_ZBrJ","executionInfo":{"status":"ok","timestamp":1675090451682,"user_tz":-60,"elapsed":6,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["def train_loop_first(data, optimizer, criterion_slots, criterion_intents, model):\n","    model.train()\n","    loss_array = []\n","    for sample in data:\n","        optimizer.zero_grad() # Zeroing the gradient\n","        slots, intent = model(sample['utterances'], sample['slots_len'])\n","        loss_intent = criterion_intents(intent, sample['intents'])\n","        loss_slot = criterion_slots(slots, sample['y_slots'])\n","        loss = loss_intent+loss_slot # In joint training we sum the losses. \n","        loss_array.append(loss.item())\n","        loss.backward() # Compute the gradient, deleting the computational graph\n","        optimizer.step() # Update the weights\n","    return loss_array\n","\n","def eval_loop_first(data, criterion_slots, criterion_intents, model, lang):\n","    model.eval()\n","    loss_array = []\n","    \n","    ref_intents = []\n","    hyp_intents = []\n","    \n","    ref_slots = []\n","    hyp_slots = []\n","    \n","    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n","    with torch.no_grad(): # It used to avoid the creation of computational graph\n","        total_slot_labels = [x for x in range (len(lang.id2slot))]\n","        total_intent_labels = [v for k, v in lang.id2intent.items()]\n","        cm_slot = np.zeros((len(total_slot_labels), len(total_slot_labels)))\n","        cm_intent = np.zeros((len(total_intent_labels), len(total_intent_labels)))\n","        for sample in data:\n","            slots, intents = model(sample['utterances'], sample['slots_len'])\n","            loss_intent = criterion_intents(intents, sample['intents'])\n","            loss_slot = criterion_slots(slots, sample['y_slots'])\n","            loss = loss_intent + loss_slot \n","            loss_array.append(loss.item())\n","            # Intent inference\n","            # Get the highest probable class\n","            out_intents = [lang.id2intent[x] \n","                           for x in torch.argmax(intents, dim=1).tolist()] \n","            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n","            ref_intents.extend(gt_intents)\n","            hyp_intents.extend(out_intents)\n","            # Slot inference \n","            output_slots = torch.argmax(slots, dim=1)\n","\n","            ref_int_labels = []\n","            hyp_int_labels = []\n","\n","            for id_seq, seq in enumerate(output_slots):\n","                length = sample['slots_len'].tolist()[id_seq]\n","                utt_ids = sample['utterance'][id_seq][:length].tolist()\n","                gt_ids = sample['y_slots'][id_seq].tolist()\n","                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n","                utterance = [lang.id2word[elem] for elem in utt_ids]\n","                to_decode = seq[:length].tolist()\n","                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n","                tmp_seq = []\n","                for id_el, elem in enumerate(to_decode):\n","                  tmp_seq.append((utterance[id_el], lang.id2slot[elem]))\n","                  ref_int_labels.extend(gt_ids[:length])\n","                  hyp_int_labels.extend(to_decode)\n","                    \n","                hyp_slots.append(tmp_seq)\n","\n","        X = [lang.id2slot[x] for x in ref_int_labels]\n","        Y = [lang.id2slot[x] for x in hyp_int_labels]\n","        labels = [lang.id2slot[x] for x in total_slot_labels]\n","\n","        cm_slot += sklearn.metrics.confusion_matrix(X, Y,labels = labels)\n","        cm_intent += sklearn.metrics.confusion_matrix(ref_intents, hyp_intents,labels = total_intent_labels)\n","    \n","    try:            \n","        results = evaluate(ref_slots, hyp_slots)\n","    except Exception as ex: #if your model predict slot that are not in ref, it gives error\n","        # Sometimes the model predics a class that is not in REF\n","        results = None\n","        \n","    report_intent = classification_report(ref_intents, hyp_intents, \n","                                          zero_division=False, output_dict=True)\n","    \n","    return results, report_intent, loss_array, cm_slot, cm_intent"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"0R7DyACGjRaG","executionInfo":{"status":"ok","timestamp":1675090451683,"user_tz":-60,"elapsed":6,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["def train_model_first(dev_loader, train_loader, test_loader, model, lang, criterion_intents, criterion_slots, optimizer):\n","  \n","    n_epochs = 200\n","    patience = 3\n","    losses_train = []\n","    losses_dev = []\n","    sampled_epochs = []\n","    best_f1 = 0\n","    for x in tqdm(range(1,n_epochs)):\n","        loss = train_loop_first(train_loader, optimizer, criterion_slots, \n","                        criterion_intents, model)\n","        if x % 5 == 0:\n","          sampled_epochs.append(x)\n","          losses_train.append(np.asarray(loss).mean())\n","          results_dev, intent_res, loss_dev, trypl, _ = eval_loop_first(dev_loader, criterion_slots, \n","                                                      criterion_intents, model, lang)\n","          losses_dev.append(np.asarray(loss_dev).mean())\n","          if results_dev != None:\n","            f1 = results_dev['total']['f-measure']\n","            acc = intent_res['accuracy']\n","            if f1 > best_f1:\n","                best_f1 = f1\n","            else:\n","                patience -= 1\n","            if patience <= 0: # Early stopping with patience\n","                break # Not nice but it keeps the code clean\n","\n","    results_test, intent_test, _, cm_slot, cm_intent = eval_loop_first(test_loader, criterion_slots, \n","                                            criterion_intents, model, lang)\n","\n","    return results_test, intent_test, sampled_epochs, losses_train, losses_dev, cm_slot, cm_intent    "]},{"cell_type":"markdown","metadata":{"id":"R5B5u2EG13Go"},"source":["## ATIS Training"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"hUUIVtxPFr-n","executionInfo":{"status":"ok","timestamp":1675090451683,"user_tz":-60,"elapsed":6,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_first_cm_slot, ATIS_first_cm_intent = initialize_confusion_matrices(ATIS_lang)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"toP8KK6c0x8g","executionInfo":{"status":"ok","timestamp":1675090456530,"user_tz":-60,"elapsed":4852,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_Firstmodel = ModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","ATIS_Firstmodel.apply(init_weights)\n","\n","ATIS_optimizer = optim.Adam(ATIS_Firstmodel.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":336103,"status":"ok","timestamp":1675090792627,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"},"user_tz":-60},"id":"fepDskZRpRt8","outputId":"0254ad51-9ee7-41c9-8416-3b980e2974b5"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 199/199 [01:27<00:00,  2.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","\n","\n","1  run\n","Intent Acc  0.936 \n","Slot F1 0.92 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|████████▉ | 179/199 [01:08<00:07,  2.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","\n","\n","2  run\n","Intent Acc  0.942 \n","Slot F1 0.925 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|████████▉ | 179/199 [01:07<00:07,  2.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","\n","\n","3  run\n","Intent Acc  0.941 \n","Slot F1 0.937 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 159/199 [01:00<00:15,  2.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","\n","\n","4  run\n","Intent Acc  0.942 \n","Slot F1 0.929 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 67%|██████▋   | 134/199 [00:51<00:24,  2.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","\n","\n","5  run\n","Intent Acc  0.925 \n","Slot F1 0.933 \n","\n","=========================================================================================\n","=========================================================================================\n","\n","Slot F1  0.929 +- 0.006\n","Intent Accuracy  0.937 +- 0.006\n","=========================================================================================\n"]}],"source":["ATIS_slots_f1s, ATIS_intents_acc = [], []\n","ATIS_intent_test_list_first, ATIS_results_test_list_first = [], []\n","for i in range(5):\n","  criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)#.to(device)\n","  criterion_intents = nn.CrossEntropyLoss()#.to(device)\n","\n","  #ATIS_Firstmodel = ModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","  ATIS_Firstmodel.apply(init_weights)\n","  ATIS_results_test, ATIS_intents_test, ATIS_sampled_epochs, ATIS_losses_train, ATIS_losses_dev, cm_slot_first_atis, cm_intent_first_atis = train_model_first(ATIS_dev_loader,\n","                                                                                                                                        ATIS_train_loader, \n","                                                                                                                                        ATIS_test_loader, \n","                                                                                                                                        ATIS_Firstmodel,\n","                                                                                                                                        ATIS_lang, \n","                                                                                                                                        criterion_intents, \n","                                                                                                                                        criterion_slots, \n","                                                                                                                                        ATIS_optimizer)\n","\n","  ATIS_intents_acc.append(ATIS_intents_test['accuracy'])\n","  ATIS_slots_f1s.append(ATIS_results_test['total']['f-measure'])\n","  ATIS_intent_test_list_first.append(ATIS_intents_test)\n","  ATIS_results_test_list_first.append(ATIS_results_test)\n","\n","  ATIS_first_cm_slot += cm_slot_first_atis\n","  ATIS_first_cm_intent += cm_intent_first_atis\n","\n","  print('='*89)\n","  print(\"\\n\")\n","  print(i+1,\" run\")\n","  print(\"Intent Acc \",round(ATIS_intents_test['accuracy'],3),\"\\nSlot F1\",round(ATIS_results_test['total']['f-measure'],3),\"\\n\")\n","  print('='*89)\n","\n","ATIS_slots_mean = np.mean(ATIS_slots_f1s)\n","ATIS_slots_std = np.std(ATIS_slots_f1s)\n","ATIS_intents_mean = np.mean(ATIS_intents_acc)\n","ATIS_intents_std = np.std(ATIS_intents_acc)\n","\n","print('='*89)\n","print('\\nSlot F1 ', round(ATIS_slots_mean,3), '+-', round(ATIS_slots_std,3))\n","print('Intent Accuracy ', round(ATIS_intents_mean,3), '+-', round(ATIS_intents_std, 3))\n","print('='*89)"]},{"cell_type":"code","source":["plot_confusion_matrix(ATIS_first_cm_intent, label=\"Intents\")\n","plot_confusion_matrix(ATIS_first_cm_slot, label=\"Slots\")"],"metadata":{"id":"k-LFTl_tLDET","executionInfo":{"status":"ok","timestamp":1675091185708,"user_tz":-60,"elapsed":737,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"76269427-aca6-4c4f-ded3-1708502531e7","colab":{"base_uri":"https://localhost:8080/","height":1000}},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"Of4q0sc-1635"},"source":["## SNIPS Training"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"9qQrFpzSFzUt","executionInfo":{"status":"ok","timestamp":1675090792628,"user_tz":-60,"elapsed":17,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_first_cm_slot, SNIPS_first_cm_intent = initialize_confusion_matrices(SNIPS_lang)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"EH2mttKa1rph","executionInfo":{"status":"ok","timestamp":1675090792629,"user_tz":-60,"elapsed":14,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_Firstmodel = ModelIAS(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","SNIPS_Firstmodel.apply(init_weights)\n","\n","SNIPS_optimizer = optim.Adam(SNIPS_Firstmodel.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362284,"status":"ok","timestamp":1675091154900,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"},"user_tz":-60},"id":"bZLxopA12xcr","outputId":"e544fce4-bd54-44c0-b654-30d31226e94d"},"outputs":[{"output_type":"stream","name":"stderr","text":[" 55%|█████▍    | 109/199 [01:43<01:25,  1.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","1  run\n","Intent Acc  0.97 \n","Slot F1 0.824 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 74/199 [01:10<01:59,  1.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","2  run\n","Intent Acc  0.963 \n","Slot F1 0.814 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 74/199 [01:11<02:00,  1.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","3  run\n","Intent Acc  0.966 \n","Slot F1 0.831 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 32%|███▏      | 64/199 [01:00<02:07,  1.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","4  run\n","Intent Acc  0.969 \n","Slot F1 0.833 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|██▉       | 59/199 [00:55<02:12,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","5  run\n","Intent Acc  0.964 \n","Slot F1 0.834 \n","\n","=========================================================================================\n","=========================================================================================\n","\n","Slot F1  0.827 +- 0.008\n","Intent Accuracy  0.966 +- 0.003\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["SNIPS_slots_f1s, SNIPS_intents_acc = [], []\n","SNIPS_intent_test_list_first, SNIPS_results_test_list_first = [], []\n","for i in range(5):\n","  criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)#.to(device)\n","  criterion_intents = nn.CrossEntropyLoss()#.to(device)\n","\n","  #ATIS_Firstmodel = ModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","  SNIPS_Firstmodel.apply(init_weights)\n","  SNIPS_results_test, SNIPS_intents_test, SNIPS_sampled_epochs, SNIPS_losses_train, SNIPS_losses_dev, cm_slot_first_snips, cm_intent_first_snips = train_model_first(SNIPS_dev_loader,\n","                                                                                                                                        SNIPS_train_loader, \n","                                                                                                                                        SNIPS_test_loader, \n","                                                                                                                                        SNIPS_Firstmodel,\n","                                                                                                                                        SNIPS_lang, \n","                                                                                                                                        criterion_intents, \n","                                                                                                                                        criterion_slots, \n","                                                                                                                                        SNIPS_optimizer)\n","\n","  SNIPS_intents_acc.append(SNIPS_intents_test['accuracy'])\n","  SNIPS_slots_f1s.append(SNIPS_results_test['total']['f-measure'])\n","  SNIPS_intent_test_list_first.append(SNIPS_intents_test)\n","  SNIPS_results_test_list_first.append(SNIPS_results_test)\n","\n","  SNIPS_first_cm_slot += cm_slot_first_snips\n","  SNIPS_first_cm_intent += cm_intent_first_snips\n","\n","  print('='*89)\n","  print(i+1,\" run\")\n","  print(\"Intent Acc \",round(SNIPS_intents_test['accuracy'],3),\"\\nSlot F1\",round(SNIPS_results_test['total']['f-measure'],3),\"\\n\")\n","  print('='*89)\n","\n","SNIPS_slots_mean = np.mean(SNIPS_slots_f1s)\n","SNIPS_slots_std = np.std(SNIPS_slots_f1s)\n","SNIPS_intents_mean = np.mean(SNIPS_intents_acc)\n","SNIPS_intents_std = np.std(SNIPS_intents_acc)\n","\n","print('='*89)\n","print('\\nSlot F1 ', round(SNIPS_slots_mean,3), '+-', round(SNIPS_slots_std,3))\n","print('Intent Accuracy ', round(SNIPS_intents_mean,3), '+-', round(SNIPS_intents_std, 3))\n","print('='*89)"]},{"cell_type":"markdown","metadata":{"id":"Rl9mtV_Q-bK7"},"source":["# Second Model"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"N2Ulbcvg7KtO","executionInfo":{"status":"ok","timestamp":1675094261431,"user_tz":-60,"elapsed":19,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["class ImprovedModelIAS(nn.Module):\n","    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=1, pad_index=0, dropout_p=0.2):\n","        super(ImprovedModelIAS, self).__init__()\n","        \n","        # Initialize the embedding layer with the given vocabulary length and embedding size\n","        self.embedding = nn.Embedding(vocab_len, emb_size, padding_idx=pad_index)\n","        # Add a dropout layer to the embeddings\n","        self.dropout = nn.Dropout(dropout_p)\n","        # Initialize the LSTM layer with the given hidden size, number of layers, and bidirectional flag\n","        self.utt_encoder = nn.LSTM(emb_size, hid_size, n_layer, bidirectional=True)    \n","        # Initialize a linear layer for producing the output for slot filling\n","        self.slot_out = nn.Linear(2 * hid_size, out_slot)  # Modify the input size to account for the bidirectional LSTM\n","        # Initialize a linear layer for producing the output for intent classification\n","        self.intent_out = nn.Linear(2 * hid_size, out_int)  # Modify the input size to account for the bidirectional LSTM\n","        \n","    def forward(self, utterance, seq_lengths):\n","        # utterance.size() = batch_size X seq_len\n","        # Convert the input utterance to embeddings\n","        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n","        # Apply dropout to the embeddings\n","        utt_emb = self.dropout(utt_emb)\n","        # Reshape the embeddings to be of size: sequence length, batch size, embedding size\n","        utt_emb = utt_emb.permute(1,0,2) # we need seq len first -> seq_len X batch_size X emb_size\n","        \n","        # Pack the padded sequence to remove the padding\n","        packed_input = pack_padded_sequence(utt_emb, seq_lengths.cpu().numpy())\n","        # Process the batch\n","        packed_output, (last_hidden, cell) = self.utt_encoder(packed_input) \n","        # Unpack the packed sequence\n","        utt_encoded, input_sizes = pad_packed_sequence(packed_output)\n","        # Get the last hidden state of the LSTM\n","        last_hidden_forward = last_hidden[0]\n","        last_hidden_backward = last_hidden[1]\n","        last_hidden = torch.cat((last_hidden_forward, last_hidden_backward), dim=1)\n","        # Compute the logits for the slot filling output\n","        slots = self.slot_out(utt_encoded)\n","        # Compute the logits for the intent classification output\n","        intent = self.intent_out(last_hidden)\n","\n","        # Slot size: seq_len, batch size, calsses  \n","        # Reshape the slots tensor to be of size: batch size, classes, sequence length for computing the loss\n","        slots = slots.permute(1,2,0) # We need this for computing the loss\n","        # Slot size: batch_size, classes, seq_len\n","        # Return the slots and intent predictions\n","        return slots, intent"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"P7FMy7DNOedI","executionInfo":{"status":"ok","timestamp":1675094261431,"user_tz":-60,"elapsed":19,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","def train_loop_second(data, optimizer, criterion_slots, criterion_intents, model):\n","    model.train()\n","    loss_array = []\n","    slot_weight=1.0\n","    intent_weight=1.0\n","    regularization=0.0\n","    for sample in data:\n","        optimizer.zero_grad() # Zeroing the gradient\n","        slots, intents = model(sample['utterances'], sample['slots_len'])\n","        loss_intent = criterion_intents(intents, sample['intents'])\n","        loss_slot = criterion_slots(slots, sample['y_slots'])\n","        loss = intent_weight*loss_intent + slot_weight*loss_slot # Weighted sum of losses\n","        # Add regularization term to the loss\n","        if regularization > 0:\n","            l2_loss = 0\n","            for param in model.parameters():\n","                l2_loss += param.pow(2).sum()\n","            loss += regularization * l2_loss\n","        loss_array.append(loss.item())\n","        loss.backward() # Compute the gradient, deleting the computational graph\n","        optimizer.step() # Update the weights\n","    return loss_array\n","\n","def eval_loop_second(data, criterion_slots, criterion_intents, model, lang):\n","    model.eval()\n","    loss_array = []\n","    \n","    ref_intents = []\n","    hyp_intents = []\n","    \n","    ref_slots = []\n","    hyp_slots = []\n","    \n","    with torch.no_grad(): # It used to avoid the creation of computational graph\n","        total_slot_labels = [x for x in range (len(lang.id2slot))]\n","        total_intent_labels = [v for k, v in lang.id2intent.items()]\n","        cm_slot = np.zeros((len(total_slot_labels), len(total_slot_labels)))\n","        cm_intent = np.zeros((len(total_intent_labels), len(total_intent_labels)))\n","        for sample in data:\n","            slots, intents = model(sample['utterances'], sample['slots_len'])\n","            loss_intent = criterion_intents(intents, sample['intents'])\n","            loss_slot = criterion_slots(slots, sample['y_slots'])\n","            loss = loss_intent + loss_slot \n","            loss_array.append(loss.item())\n","            # Intent inference\n","            # Get the highest probable class\n","            out_intents = [lang.id2intent[x] \n","                           for x in torch.argmax(intents, dim=1).tolist()] \n","            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n","            ref_intents.extend(gt_intents)\n","            hyp_intents.extend(out_intents)\n","            # Slot inference \n","            output_slots = torch.argmax(slots, dim=1)\n","\n","            ref_int_labels = []\n","            hyp_int_labels = []\n","\n","            for id_seq, seq in enumerate(output_slots):\n","                length = sample['slots_len'].tolist()[id_seq]\n","                utt_ids = sample['utterance'][id_seq][:length].tolist()\n","                gt_ids = sample['y_slots'][id_seq].tolist()\n","                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n","                utterance = [lang.id2word[elem] for elem in utt_ids]\n","                to_decode = seq[:length].tolist()\n","                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n","                tmp_seq = []\n","                for id_el, elem in enumerate(to_decode):\n","                  tmp_seq.append((utterance[id_el], lang.id2slot[elem]))\n","                  ref_int_labels.extend(gt_ids[:length])\n","                  hyp_int_labels.extend(to_decode)\n","                    \n","                hyp_slots.append(tmp_seq)\n","\n","        X = [lang.id2slot[x] for x in ref_int_labels]\n","        Y = [lang.id2slot[x] for x in hyp_int_labels]\n","        labels = [lang.id2slot[x] for x in total_slot_labels]\n","\n","        cm_slot += sklearn.metrics.confusion_matrix(X, Y,labels = labels)\n","        cm_intent += sklearn.metrics.confusion_matrix(ref_intents, hyp_intents,labels = total_intent_labels)\n","    \n","    try:            \n","        results = evaluate(ref_slots, hyp_slots)\n","    except Exception as ex: #if your model predict slot that are not in ref, it gives error\n","        # Sometimes the model predics a class that is not in REF\n","        results = None\n","        \n","    report_intent = classification_report(ref_intents, hyp_intents, \n","                                          zero_division=False, output_dict=True)\n","    \n","    return results, report_intent, loss_array, cm_slot, cm_intent\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"dufHA0lfQQ4q","executionInfo":{"status":"ok","timestamp":1675094261432,"user_tz":-60,"elapsed":18,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["def train_model_second(dev_loader, train_loader, test_loader, model, lang, criterion_intents, criterion_slots, optimizer):\n","    \n","    n_epochs = 200\n","    patience = 3\n","    losses_train = []\n","    losses_dev = []\n","    sampled_epochs = []\n","    best_f1 = 0\n","    for x in tqdm(range(1,n_epochs)):\n","        loss = train_loop_second(train_loader, optimizer, criterion_slots, criterion_intents, model)\n","        if x % 5 == 0:\n","          sampled_epochs.append(x)\n","          losses_train.append(np.asarray(loss).mean())\n","          results_dev, intent_res, loss_dev, trypl, _ = eval_loop_second(dev_loader, criterion_slots, criterion_intents, model, lang)\n","          losses_dev.append(np.asarray(loss_dev).mean())\n","          if results_dev != None:\n","            f1 = results_dev['total']['f-measure']\n","            acc = intent_res['accuracy']\n","            if f1 > best_f1:\n","                best_f1 = f1\n","            else:\n","                patience -= 1\n","            if patience <= 0: # Early stopping with patience\n","                break # Not nice but it keeps the code clean\n","\n","    results_test, intent_test, _, cm_slot, cm_intent = eval_loop_second(test_loader, criterion_slots, \n","                                            criterion_intents, model, lang)\n","\n","    return results_test, intent_test, sampled_epochs, losses_train, losses_dev, cm_slot, cm_intent  "]},{"cell_type":"code","execution_count":24,"metadata":{"id":"taSKurfFarSj","executionInfo":{"status":"ok","timestamp":1675094261432,"user_tz":-60,"elapsed":17,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["def train_model_second_loss(dev_loader, train_loader, test_loader, model, lang, criterion_intents, criterion_slots, optimizer):\n","    \n","    n_epochs = 200\n","    patience = 3\n","    losses_train = []\n","    losses_dev = []\n","    sampled_epochs = []\n","    best_f1 = 0\n","    for x in tqdm(range(1,n_epochs)):\n","        loss = train_loop_first(train_loader, optimizer, criterion_slots, criterion_intents, model)\n","        if x % 5 == 0:\n","          sampled_epochs.append(x)\n","          losses_train.append(np.asarray(loss).mean())\n","          results_dev, intent_res, loss_dev, trypl, _ = eval_loop_first(dev_loader, criterion_slots, criterion_intents, model, lang)\n","          losses_dev.append(np.asarray(loss_dev).mean())\n","          if results_dev != None:\n","            f1 = results_dev['total']['f-measure']\n","            acc = intent_res['accuracy']\n","            if f1 > best_f1:\n","                best_f1 = f1\n","            else:\n","                patience -= 1\n","            if patience <= 0: # Early stopping with patience\n","                break # Not nice but it keeps the code clean\n","\n","    results_test, intent_test, _, cm_slot, cm_intent = eval_loop_first(test_loader, criterion_slots, \n","                                            criterion_intents, model, lang)\n","\n","    return results_test, intent_test, sampled_epochs, losses_train, losses_dev, cm_slot, cm_intent  "]},{"cell_type":"markdown","metadata":{"id":"iuryU4ILzPKY"},"source":["## ATIS Training"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"zCxOIePUHAp9","executionInfo":{"status":"ok","timestamp":1675094261432,"user_tz":-60,"elapsed":16,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_second_cm_slot, ATIS_second_cm_intent = initialize_confusion_matrices(ATIS_lang)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"Srcmr2brS-fF","executionInfo":{"status":"ok","timestamp":1675094266340,"user_tz":-60,"elapsed":4924,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_Secondmodel = ImprovedModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","ATIS_Secondmodel.apply(init_weights)\n","\n","ATIS_optimizer = optim.Adam(ATIS_Secondmodel.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269735,"status":"ok","timestamp":1675094536068,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"},"user_tz":-60},"id":"ZIafq2QGQRD-","outputId":"02054c30-6a55-435f-9c0b-33dad41bb0d9"},"outputs":[{"output_type":"stream","name":"stderr","text":[" 75%|███████▍  | 149/199 [01:11<00:24,  2.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","\n","\n","1  run\n","Intent Acc  0.953 \n","Slot F1 0.941 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▍   | 129/199 [00:59<00:32,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","\n","\n","2  run\n","Intent Acc  0.953 \n","Slot F1 0.943 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 119/199 [00:55<00:37,  2.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","\n","\n","3  run\n","Intent Acc  0.96 \n","Slot F1 0.944 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 42%|████▏     | 84/199 [00:39<00:53,  2.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","\n","\n","4  run\n","Intent Acc  0.955 \n","Slot F1 0.941 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▍     | 89/199 [00:41<00:51,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","\n","\n","5  run\n","Intent Acc  0.96 \n","Slot F1 0.946 \n","\n","=========================================================================================\n","=========================================================================================\n","\n","Slot F1  0.943 +- 0.002\n","Intent Accuracy  0.956 +- 0.003\n","=========================================================================================\n"]}],"source":["# 5 epoche\n","ATIS_slots_f1s, ATIS_intents_acc = [], []\n","ATIS_intent_test_list_second, ATIS_results_test_list_second = [], []\n","for i in range(5):\n","  criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)#.to(device)\n","  criterion_intents = nn.CrossEntropyLoss()#.to(device)\n","\n","  #ATIS_Firstmodel = ModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","  ATIS_Secondmodel.apply(init_weights)\n","  ATIS_results_test, ATIS_intents_test, ATIS_sampled_epochs, ATIS_losses_train, ATIS_losses_dev, cm_slot_second_atis, cm_intent_second_atis = train_model_second(ATIS_dev_loader,\n","                                                                                                                                        ATIS_train_loader, \n","                                                                                                                                        ATIS_test_loader, \n","                                                                                                                                        ATIS_Secondmodel,\n","                                                                                                                                        ATIS_lang, \n","                                                                                                                                        criterion_intents, \n","                                                                                                                                        criterion_slots, \n","                                                                                                                                        ATIS_optimizer)\n","\n","  ATIS_intents_acc.append(ATIS_intents_test['accuracy'])\n","  ATIS_slots_f1s.append(ATIS_results_test['total']['f-measure'])\n","  ATIS_intent_test_list_second.append(ATIS_intents_test)\n","  ATIS_results_test_list_second.append(ATIS_results_test)\n","\n","  ATIS_second_cm_slot += cm_slot_second_atis\n","  ATIS_second_cm_intent += cm_intent_second_atis\n","\n","  print('='*89)\n","  print(\"\\n\")\n","  print(i+1,\" run\")\n","  print(\"Intent Acc \",round(ATIS_intents_test['accuracy'],3),\"\\nSlot F1\",round(ATIS_results_test['total']['f-measure'],3),\"\\n\")\n","  print('='*89)\n","\n","ATIS_slots_mean = np.mean(ATIS_slots_f1s)\n","ATIS_slots_std = np.std(ATIS_slots_f1s)\n","ATIS_intents_mean = np.mean(ATIS_intents_acc)\n","ATIS_intents_std = np.std(ATIS_intents_acc)\n","\n","print('='*89)\n","print('\\nSlot F1 ', round(ATIS_slots_mean,3), '+-', round(ATIS_slots_std,3))\n","print('Intent Accuracy ', round(ATIS_intents_mean,3), '+-', round(ATIS_intents_std, 3))\n","print('='*89)"]},{"cell_type":"markdown","metadata":{"id":"rul8DUzGzU3a"},"source":["## SNIPS Training"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"LACM5u-qHF3X","executionInfo":{"status":"ok","timestamp":1675094536069,"user_tz":-60,"elapsed":20,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_second_cm_slot, SNIPS_second_cm_intent = initialize_confusion_matrices(SNIPS_lang)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"gxOM7pgQzX0e","executionInfo":{"status":"ok","timestamp":1675094536070,"user_tz":-60,"elapsed":13,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_secondmodel = ImprovedModelIAS(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","SNIPS_secondmodel.apply(init_weights)\n","\n","SNIPS_optimizer = optim.Adam(SNIPS_secondmodel.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":496623,"status":"ok","timestamp":1675095032682,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"},"user_tz":-60},"id":"8PPPYL21zUgC","outputId":"5e8c426c-a5b3-400f-eedc-ece14c02e398"},"outputs":[{"output_type":"stream","name":"stderr","text":[" 55%|█████▍    | 109/199 [02:05<01:43,  1.15s/it]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","1  run\n","Intent Acc  0.969 \n","Slot F1 0.879 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 79/199 [01:31<02:18,  1.15s/it]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","2  run\n","Intent Acc  0.973 \n","Slot F1 0.877 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 79/199 [01:30<02:17,  1.15s/it]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","3  run\n","Intent Acc  0.97 \n","Slot F1 0.884 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 42%|████▏     | 84/199 [01:36<02:12,  1.15s/it]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","4  run\n","Intent Acc  0.969 \n","Slot F1 0.876 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 79/199 [01:31<02:18,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","5  run\n","Intent Acc  0.976 \n","Slot F1 0.877 \n","\n","=========================================================================================\n","=========================================================================================\n","\n","Slot F1  0.879 +- 0.003\n","Intent Accuracy  0.971 +- 0.003\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["SNIPS_slots_f1s, SNIPS_intents_acc = [], []\n","SNIPS_intent_test_list_second, SNIPS_results_test_list_second = [], []\n","for i in range(5):\n","  criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)#.to(device)\n","  criterion_intents = nn.CrossEntropyLoss()#.to(device)\n","\n","  #ATIS_Firstmodel = ModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","  SNIPS_secondmodel.apply(init_weights)\n","  SNIPS_results_test, SNIPS_intents_test, SNIPS_sampled_epochs, SNIPS_losses_train, SNIPS_losses_dev, cm_slot_second_snips, cm_intent_second_snips = train_model_second(SNIPS_dev_loader,\n","                                                                                                                                        SNIPS_train_loader, \n","                                                                                                                                        SNIPS_test_loader, \n","                                                                                                                                        SNIPS_secondmodel,\n","                                                                                                                                        SNIPS_lang, \n","                                                                                                                                        criterion_intents, \n","                                                                                                                                        criterion_slots, \n","                                                                                                                                        SNIPS_optimizer)\n","\n","  SNIPS_intents_acc.append(SNIPS_intents_test['accuracy'])\n","  SNIPS_slots_f1s.append(SNIPS_results_test['total']['f-measure'])\n","  SNIPS_intent_test_list_second.append(SNIPS_intents_test)\n","  SNIPS_results_test_list_second.append(SNIPS_results_test)\n","\n","  SNIPS_second_cm_slot += cm_slot_second_snips\n","  SNIPS_second_cm_intent += cm_intent_second_snips\n","\n","  print('='*89)\n","  print(i+1,\" run\")\n","  print(\"Intent Acc \",round(SNIPS_intents_test['accuracy'],3),\"\\nSlot F1\",round(SNIPS_results_test['total']['f-measure'],3),\"\\n\")\n","  print('='*89)\n","\n","SNIPS_slots_mean = np.mean(SNIPS_slots_f1s)\n","SNIPS_slots_std = np.std(SNIPS_slots_f1s)\n","SNIPS_intents_mean = np.mean(SNIPS_intents_acc)\n","SNIPS_intents_std = np.std(SNIPS_intents_acc)\n","\n","print('='*89)\n","print('\\nSlot F1 ', round(SNIPS_slots_mean,3), '+-', round(SNIPS_slots_std,3))\n","print('Intent Accuracy ', round(SNIPS_intents_mean,3), '+-', round(SNIPS_intents_std, 3))\n","print('='*89)"]},{"cell_type":"markdown","metadata":{"id":"MP4BS9X8c-JF"},"source":["# Third Model"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"fxXIDQYEQhHu","executionInfo":{"status":"ok","timestamp":1675093491111,"user_tz":-60,"elapsed":16,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["from torch.nn.functional import softmax\n","\n","# A flag indicating whether the model uses a bidirectional GRU for encoding.\n","bidirectional = True\n","\n","class AttentionModelIAS(nn.Module):\n","    \n","    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=1, pad_index=0, dropout_p=0.2):\n","        super(AttentionModelIAS, self).__init__()\n","\n","        # Embedding layer that maps vocabulary indices to embedding vectors\n","        self.embedding = nn.Embedding(vocab_len, emb_size, padding_idx=pad_index)\n","        # GRU layer for encoding input sequences\n","        self.encoder = nn.GRU(emb_size, hid_size, bidirectional=bidirectional, num_layers=n_layer, dropout=dropout_p)\n","        # Depending on the bidirectional flag, determine the architecture for the attention mechanism and the classifiers\n","        if bidirectional:\n","            self.attention = nn.Linear(hid_size*2, 1)\n","\n","            self.intent_classifier = nn.Linear(hid_size*2, out_int)\n","            self.slot_filler = nn.Linear(hid_size*2, out_slot)\n","        else:\n","            self.attention = nn.Linear(hid_size, 1)\n","            \n","            self.intent_classifier = nn.Linear(hid_size, out_int)\n","            self.slot_filler = nn.Linear(hid_size, out_slot)\n","\n","\n","    def forward(self, input_seq, seq_lengths):\n","        # Transpose the input sequences for processing\n","        input_seq = input_seq.permute(1, 0)\n","        # Obtain the embedding vectors for the input sequences\n","        embedded = self.embedding(input_seq)\n","        # Pack the embedding vectors for processing with a GRU\n","        embedded = nn.utils.rnn.pack_padded_sequence(embedded, seq_lengths.cpu())\n","        # Perform encoding on the input sequences with a GRU\n","        encoder_output, encoder_hidden = self.encoder(embedded)\n","        # Unpack the encoded sequences\n","        encoder_output, _ = nn.utils.rnn.pad_packed_sequence(encoder_output)\n","        # Transpose the encoded sequences\n","        encoder_output = encoder_output.permute(1, 0, 2)\n","\n","        # Compute attention context for intent classification\n","        attention_scores = self.attention(encoder_output)\n","        # Obtain the attention weights as the softmax of the attention scores\n","        attention_weights = torch.softmax(attention_scores, dim=-1)\n","        attention_context = torch.sum(attention_weights * encoder_output, dim=-2)\n","        \n","        # Intent classification\n","        intent_logits = self.intent_classifier(attention_context)\n","\n","        # weight the slot logits by attention weights\n","        slot_logits = self.slot_filler(encoder_output)\n","        slot_logits = slot_logits * attention_weights\n","        slot_logits = slot_logits.permute(0, 2, 1)\n","\n","        return slot_logits, intent_logits"]},{"cell_type":"markdown","metadata":{"id":"zn_uXxTA5Dec"},"source":["## Monodirectional with dropout = 0.2 and the baseline loss"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"6tWZdLXS-RxT","executionInfo":{"status":"ok","timestamp":1675093492817,"user_tz":-60,"elapsed":2,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","def train_loop_third_monodirectional(data, optimizer, criterion_slots, criterion_intents, model): #SIMPLE VERSION\n","    model.train()\n","    loss_array = []\n","    for sample in data:\n","        optimizer.zero_grad() # Zeroing the gradient\n","        slots, intent = model(sample['utterances'], sample['slots_len'])\n","        loss_intent = criterion_intents(intent, sample['intents'])\n","        loss_slot = criterion_slots(slots, sample['y_slots'])\n","        loss = loss_intent+loss_slot # In joint training we sum the losses. \n","        loss_array.append(loss.item())\n","        loss.backward() # Compute the gradient, deleting the computational graph\n","        optimizer.step() # Update the weights\n","    return loss_array\n","\n","def eval_loop_third_monodirectional(data, criterion_slots, criterion_intents, model, lang):\n","    model.eval()\n","    loss_array = []\n","    \n","    ref_intents = []\n","    hyp_intents = []\n","    \n","    ref_slots = []\n","    hyp_slots = []\n","    \n","    with torch.no_grad(): # It used to avoid the creation of computational graph\n","        total_slot_labels = [x for x in range (len(lang.id2slot))]\n","        total_intent_labels = [v for k, v in lang.id2intent.items()]\n","        cm_slot = np.zeros((len(total_slot_labels), len(total_slot_labels)))\n","        cm_intent = np.zeros((len(total_intent_labels), len(total_intent_labels)))\n","        for sample in data:\n","            slots, intents = model(sample['utterances'], sample['slots_len'])\n","            loss_intent = criterion_intents(intents, sample['intents'])\n","            loss_slot = criterion_slots(slots, sample['y_slots'])\n","            loss = loss_intent + loss_slot \n","            loss_array.append(loss.item())\n","            # Intent inference\n","            # Get the highest probable class\n","            out_intents = [lang.id2intent[x] \n","                           for x in torch.argmax(intents, dim=1).tolist()] \n","            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n","            ref_intents.extend(gt_intents)\n","            hyp_intents.extend(out_intents)\n","            # Slot inference \n","            output_slots = torch.argmax(slots, dim=1)\n","\n","            ref_int_labels = []\n","            hyp_int_labels = []\n","\n","            for id_seq, seq in enumerate(output_slots):\n","                length = sample['slots_len'].tolist()[id_seq]\n","                utt_ids = sample['utterance'][id_seq][:length].tolist()\n","                gt_ids = sample['y_slots'][id_seq].tolist()\n","                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n","                utterance = [lang.id2word[elem] for elem in utt_ids]\n","                to_decode = seq[:length].tolist()\n","                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n","                tmp_seq = []\n","                for id_el, elem in enumerate(to_decode):\n","                  tmp_seq.append((utterance[id_el], lang.id2slot[elem]))\n","                  ref_int_labels.extend(gt_ids[:length])\n","                  hyp_int_labels.extend(to_decode)\n","                    \n","                hyp_slots.append(tmp_seq)\n","\n","        X = [lang.id2slot[x] for x in ref_int_labels]\n","        Y = [lang.id2slot[x] for x in hyp_int_labels]\n","        labels = [lang.id2slot[x] for x in total_slot_labels]\n","\n","        cm_slot += sklearn.metrics.confusion_matrix(X, Y,labels = labels)\n","        cm_intent += sklearn.metrics.confusion_matrix(ref_intents, hyp_intents,labels = total_intent_labels)\n","    \n","    try:            \n","        results = evaluate(ref_slots, hyp_slots)\n","    except Exception as ex: #if your model predict slot that are not in ref, it gives error\n","        # Sometimes the model predics a class that is not in REF\n","        results = None\n","        \n","    report_intent = classification_report(ref_intents, hyp_intents, \n","                                          zero_division=False, output_dict=True)\n","    \n","    return results, report_intent, loss_array, cm_slot, cm_intent"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"TVA2iGqYRvvu","executionInfo":{"status":"ok","timestamp":1675092090072,"user_tz":-60,"elapsed":7,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["def train_model_third_monodirectional(dev_loader, train_loader, test_loader, model, lang, criterion_intents, criterion_slots, optimizer):\n","    \n","    n_epochs = 200\n","    patience = 3\n","    losses_train = []\n","    losses_dev = []\n","    sampled_epochs = []\n","    best_f1 = 0\n","    for x in tqdm(range(1,n_epochs)):\n","        loss = train_loop_third_monodirectional(train_loader, optimizer, criterion_slots, criterion_intents, model)\n","        if x % 5 == 0:\n","          sampled_epochs.append(x)\n","          losses_train.append(np.asarray(loss).mean())\n","          results_dev, intent_res, loss_dev, trypl, _ = eval_loop_third_monodirectional(dev_loader, criterion_slots, criterion_intents, model, lang)\n","          losses_dev.append(np.asarray(loss_dev).mean())\n","          if results_dev != None:\n","            f1 = results_dev['total']['f-measure']\n","            acc = intent_res['accuracy']\n","            if f1 > best_f1:\n","                best_f1 = f1\n","            else:\n","                patience -= 1\n","            if patience <= 0: # Early stopping with patience\n","                break # Not nice but it keeps the code clean\n","\n","    results_test, intent_test, _, cm_slot, cm_intent = eval_loop_third_monodirectional(test_loader, criterion_slots, \n","                                            criterion_intents, model, lang)\n","\n","    return results_test, intent_test, sampled_epochs, losses_train, losses_dev, cm_slot, cm_intent  "]},{"cell_type":"markdown","metadata":{"id":"Aehuw4IS_W63"},"source":["### ATIS "]},{"cell_type":"code","execution_count":88,"metadata":{"id":"MaU4SeoQH_w8","executionInfo":{"status":"ok","timestamp":1675092090072,"user_tz":-60,"elapsed":7,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_third_monodirectional_cm_slot, ATIS_third_monodirectional_cm_intent = initialize_confusion_matrices(ATIS_lang)"]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1675092090072,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"},"user_tz":-60},"id":"FExb_fKA5IPf","outputId":"3b3d713e-60b8-475b-aa96-4b32c145f55b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]}],"source":["ATIS_Thirdmodel = AttentionModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","ATIS_Thirdmodel.apply(init_weights)\n","\n","ATIS_optimizer = optim.Adam(ATIS_Thirdmodel.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JW1czVBc5Jyp","outputId":"382de63a-6808-4219-9334-91743529c6df","executionInfo":{"status":"ok","timestamp":1675092377702,"user_tz":-60,"elapsed":287635,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[{"output_type":"stream","name":"stderr","text":[" 90%|████████▉ | 179/199 [01:23<00:09,  2.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","1  run\n","Intent Acc  0.953 \n","Slot F1 0.946 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 52%|█████▏    | 104/199 [00:48<00:44,  2.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","2  run\n","Intent Acc  0.953 \n","Slot F1 0.942 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 57%|█████▋    | 114/199 [00:53<00:39,  2.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","3  run\n","Intent Acc  0.946 \n","Slot F1 0.945 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|████▉     | 99/199 [00:46<00:47,  2.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","4  run\n","Intent Acc  0.951 \n","Slot F1 0.944 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 57%|█████▋    | 114/199 [00:54<00:40,  2.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","5  run\n","Intent Acc  0.952 \n","Slot F1 0.944 \n","\n","=========================================================================================\n","=========================================================================================\n","\n","Slot F1  0.944 +- 0.002\n","Intent Accuracy  0.951 +- 0.002\n","=========================================================================================\n"]}],"source":["ATIS_slots_f1s, ATIS_intents_acc = [], []\n","ATIS_intent_test_list_third_monodirectional, ATIS_results_test_list_third_monodirectional = [], []\n","for i in range(5):\n","  criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)#.to(device)\n","  criterion_intents = nn.CrossEntropyLoss()#.to(device)\n","  #ATIS_Firstmodel = ModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","  ATIS_Thirdmodel.apply(init_weights)\n","  ATIS_results_test, ATIS_intents_test, ATIS_sampled_epochs, ATIS_losses_train, ATIS_losses_dev, cm_atis_third_monodirectional_slot, cm_atis_third_monodirectional_intent = train_model_third_monodirectional(ATIS_dev_loader,\n","                                                                                                                                        ATIS_train_loader, \n","                                                                                                                                        ATIS_test_loader, \n","                                                                                                                                        ATIS_Thirdmodel,\n","                                                                                                                                        ATIS_lang, \n","                                                                                                                                        criterion_intents, \n","                                                                                                                                        criterion_slots, \n","                                                                                                                                        ATIS_optimizer)\n","\n","  ATIS_intents_acc.append(ATIS_intents_test['accuracy'])\n","  ATIS_slots_f1s.append(ATIS_results_test['total']['f-measure'])\n","  ATIS_intent_test_list_third_monodirectional.append(ATIS_intents_test)\n","  ATIS_results_test_list_third_monodirectional.append(ATIS_results_test)\n","\n","  ATIS_third_monodirectional_cm_slot += cm_atis_third_monodirectional_slot\n","  ATIS_third_monodirectional_cm_intent += cm_atis_third_monodirectional_intent\n","\n","  print('='*89)\n","  print(i+1,\" run\")\n","  print(\"Intent Acc \",round(ATIS_intents_test['accuracy'],3),\"\\nSlot F1\",round(ATIS_results_test['total']['f-measure'],3),\"\\n\")\n","  print('='*89)\n","\n","ATIS_slots_mean = np.mean(ATIS_slots_f1s)\n","ATIS_slots_std = np.std(ATIS_slots_f1s)\n","ATIS_intents_mean = np.mean(ATIS_intents_acc)\n","ATIS_intents_std = np.std(ATIS_intents_acc)\n","\n","print('='*89)\n","print('\\nSlot F1 ', round(ATIS_slots_mean,3), '+-', round(ATIS_slots_std,3))\n","print('Intent Accuracy ', round(ATIS_intents_mean,3), '+-', round(ATIS_intents_std, 3))\n","print('='*89)"]},{"cell_type":"markdown","metadata":{"id":"Zi2TxjMv_mWT"},"source":["### SNIPS"]},{"cell_type":"code","execution_count":91,"metadata":{"id":"diy3xcBLIUaA","executionInfo":{"status":"ok","timestamp":1675092377703,"user_tz":-60,"elapsed":11,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_third_monodirectional_cm_slot, SNIPS_third_monodirectional_cm_intent = initialize_confusion_matrices(SNIPS_lang)"]},{"cell_type":"code","execution_count":92,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2uJE7Few_zJH","outputId":"6e4486f3-5106-4bc2-bdad-7600508ede05","executionInfo":{"status":"ok","timestamp":1675092377704,"user_tz":-60,"elapsed":9,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]}],"source":["SNIPS_Thirdmodel = AttentionModelIAS(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","SNIPS_Thirdmodel.apply(init_weights)\n","\n","SNIPS_optimizer = optim.Adam(SNIPS_Thirdmodel.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"mJdhig7x_40J","outputId":"f8836c79-3da7-42a6-d04b-32a46de5413a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675092744202,"user_tz":-60,"elapsed":366505,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 74/199 [01:27<02:28,  1.19s/it]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","1  run\n","Intent Acc  0.963 \n","Slot F1 0.849 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▍      | 69/199 [01:20<02:31,  1.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","2  run\n","Intent Acc  0.966 \n","Slot F1 0.854 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 74/199 [01:26<02:26,  1.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","3  run\n","Intent Acc  0.963 \n","Slot F1 0.846 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|█▉        | 39/199 [00:46<03:12,  1.20s/it]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","4  run\n","Intent Acc  0.966 \n","Slot F1 0.847 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 27%|██▋       | 54/199 [01:03<02:51,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","5  run\n","Intent Acc  0.966 \n","Slot F1 0.856 \n","\n","=========================================================================================\n","=========================================================================================\n","\n","Slot F1  0.85 +- 0.004\n","Intent Accuracy  0.965 +- 0.001\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["SNIPS_slots_f1s, SNIPS_intents_acc = [], []\n","SNIPS_intent_test_list_third_monodirectional, SNIPS_results_test_list_third_monodirectional = [], []\n","for i in range(5):\n","  criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)#.to(device)\n","  criterion_intents = nn.CrossEntropyLoss()#.to(device)\n","  #ATIS_Firstmodel = ModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","  SNIPS_Thirdmodel.apply(init_weights)\n","  SNIPS_results_test, SNIPS_intents_test, SNIPS_sampled_epochs, SNIPS_losses_train, SNIPS_losses_dev, cm_slot_third_monodirectional_snips, cm_intent_third_monodirectional_snips = train_model_third_monodirectional(SNIPS_dev_loader,\n","                                                                                                                                        SNIPS_train_loader, \n","                                                                                                                                        SNIPS_test_loader, \n","                                                                                                                                        SNIPS_Thirdmodel,\n","                                                                                                                                        SNIPS_lang, \n","                                                                                                                                        criterion_intents, \n","                                                                                                                                        criterion_slots, \n","                                                                                                                                        SNIPS_optimizer)\n","\n","  SNIPS_intents_acc.append(SNIPS_intents_test['accuracy'])\n","  SNIPS_slots_f1s.append(SNIPS_results_test['total']['f-measure'])\n","  SNIPS_intent_test_list_third_monodirectional.append(SNIPS_intents_test)\n","  SNIPS_results_test_list_third_monodirectional.append(SNIPS_results_test)\n","\n","  SNIPS_third_monodirectional_cm_slot += cm_slot_third_monodirectional_snips\n","  SNIPS_third_monodirectional_cm_intent += cm_intent_third_monodirectional_snips\n","\n","  print('='*89)\n","  print(i+1,\" run\")\n","  print(\"Intent Acc \",round(SNIPS_intents_test['accuracy'],3),\"\\nSlot F1\",round(SNIPS_results_test['total']['f-measure'],3),\"\\n\")\n","  print('='*89)\n","\n","SNIPS_slots_mean = np.mean(SNIPS_slots_f1s)\n","SNIPS_slots_std = np.std(SNIPS_slots_f1s)\n","SNIPS_intents_mean = np.mean(SNIPS_intents_acc)\n","SNIPS_intents_std = np.std(SNIPS_intents_acc)\n","\n","print('='*89)\n","print('\\nSlot F1 ', round(SNIPS_slots_mean,3), '+-', round(SNIPS_slots_std,3))\n","print('Intent Accuracy ', round(SNIPS_intents_mean,3), '+-', round(SNIPS_intents_std, 3))\n","print('='*89)"]},{"cell_type":"markdown","metadata":{"id":"iE-toJsv4vxs"},"source":["## Bidirectional with dropout 0.2 (and loss = max(loss_intent, loss_slot) * max(weights[0], weights[1]) + min(loss_intent, loss_slot) * min(weights[0], weights[1])) "]},{"cell_type":"code","execution_count":23,"metadata":{"id":"jYRVcli--GBJ","executionInfo":{"status":"ok","timestamp":1675093538695,"user_tz":-60,"elapsed":519,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","def train_loop_third_bidirectional(data, optimizer, criterion_slots, criterion_intents, model):\n","    model.train()\n","    loss_array = []\n","    for sample in data:\n","        optimizer.zero_grad() # Zeroing the gradient\n","        slots, intent = model(sample['utterances'], sample['slots_len'])\n","        loss_intent = criterion_intents(intent, sample['intents'])\n","        loss_slot = criterion_slots(slots, sample['y_slots'])\n","        weights, _ = torch.sort (nn.functional.softmax(torch. randn (2), dim=-1))\n","        loss = max(loss_intent, loss_slot) * max(weights[0], weights[1]) + min(loss_intent, loss_slot) * min(weights[0], weights[1])\n","        loss_array.append(loss.item())\n","        loss.backward() # Compute the gradient, deleting the computational graph\n","        optimizer.step() # Update the weights\n","    return loss_array\n","\n","def eval_loop_third_bidirectional(data, criterion_slots, criterion_intents, model, lang):\n","    model.eval()\n","    loss_array = []\n","    \n","    ref_intents = []\n","    hyp_intents = []\n","    \n","    ref_slots = []\n","    hyp_slots = []\n","    \n","    with torch.no_grad(): # It used to avoid the creation of computational graph\n","        total_slot_labels = [x for x in range (len(lang.id2slot))]\n","        total_intent_labels = [v for k, v in lang.id2intent.items()]\n","        cm_slot = np.zeros((len(total_slot_labels), len(total_slot_labels)))\n","        cm_intent = np.zeros((len(total_intent_labels), len(total_intent_labels)))\n","        for sample in data:\n","            slots, intents = model(sample['utterances'], sample['slots_len'])\n","            loss_intent = criterion_intents(intents, sample['intents'])\n","            loss_slot = criterion_slots(slots, sample['y_slots'])\n","            loss = loss_intent + loss_slot \n","            loss_array.append(loss.item())\n","            # Intent inference\n","            # Get the highest probable class\n","            out_intents = [lang.id2intent[x] \n","                           for x in torch.argmax(intents, dim=1).tolist()] \n","            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n","            ref_intents.extend(gt_intents)\n","            hyp_intents.extend(out_intents)\n","            # Slot inference \n","            output_slots = torch.argmax(slots, dim=1)\n","\n","            ref_int_labels = []\n","            hyp_int_labels = []\n","\n","            for id_seq, seq in enumerate(output_slots):\n","                length = sample['slots_len'].tolist()[id_seq]\n","                utt_ids = sample['utterance'][id_seq][:length].tolist()\n","                gt_ids = sample['y_slots'][id_seq].tolist()\n","                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n","                utterance = [lang.id2word[elem] for elem in utt_ids]\n","                to_decode = seq[:length].tolist()\n","                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n","                tmp_seq = []\n","                for id_el, elem in enumerate(to_decode):\n","                  tmp_seq.append((utterance[id_el], lang.id2slot[elem]))\n","                  ref_int_labels.extend(gt_ids[:length])\n","                  hyp_int_labels.extend(to_decode)\n","                    \n","                hyp_slots.append(tmp_seq)\n","\n","        X = [lang.id2slot[x] for x in ref_int_labels]\n","        Y = [lang.id2slot[x] for x in hyp_int_labels]\n","        labels = [lang.id2slot[x] for x in total_slot_labels]\n","\n","        cm_slot += sklearn.metrics.confusion_matrix(X, Y,labels = labels)\n","        cm_intent += sklearn.metrics.confusion_matrix(ref_intents, hyp_intents,labels = total_intent_labels)\n","    \n","    try:            \n","        results = evaluate(ref_slots, hyp_slots)\n","    except Exception as ex: #if your model predict slot that are not in ref, it gives error\n","        # Sometimes the model predics a class that is not in REF\n","        results = None\n","        \n","    report_intent = classification_report(ref_intents, hyp_intents, \n","                                          zero_division=False, output_dict=True)\n","    \n","    return results, report_intent, loss_array, cm_slot, cm_intent\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"lWU7Z1as96jN","executionInfo":{"status":"ok","timestamp":1675093539210,"user_tz":-60,"elapsed":3,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["def train_model_third_bidirectional(dev_loader, train_loader, test_loader, model, lang, criterion_intents, criterion_slots, optimizer):\n","    \n","    n_epochs = 200\n","    patience = 3\n","    losses_train = []\n","    losses_dev = []\n","    sampled_epochs = []\n","    best_f1 = 0\n","    for x in tqdm(range(1,n_epochs)):\n","        loss = train_loop_third_bidirectional(train_loader, optimizer, criterion_slots, criterion_intents, model)\n","        if x % 5 == 0:\n","          sampled_epochs.append(x)\n","          losses_train.append(np.asarray(loss).mean())\n","          results_dev, intent_res, loss_dev, trypl, _ = eval_loop_third_bidirectional(dev_loader, criterion_slots, criterion_intents, model, lang)\n","          losses_dev.append(np.asarray(loss_dev).mean())\n","          if results_dev != None:\n","            f1 = results_dev['total']['f-measure']\n","            acc = intent_res['accuracy']\n","            if f1 > best_f1:\n","                best_f1 = f1\n","            else:\n","                patience -= 1\n","            if patience <= 0: # Early stopping with patience\n","                break # Not nice but it keeps the code clean\n","\n","    results_test, intent_test, _, cm_slot, cm_intent = eval_loop_third_bidirectional(test_loader, criterion_slots, \n","                                            criterion_intents, model, lang)\n","\n","    return results_test, intent_test, sampled_epochs, losses_train, losses_dev, cm_slot, cm_intent  "]},{"cell_type":"markdown","metadata":{"id":"XSeYfV7p_dZb"},"source":["### ATIS"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"BXAKga8vKuAl","executionInfo":{"status":"ok","timestamp":1675093542487,"user_tz":-60,"elapsed":6,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_third_bidirectional_cm_slot, ATIS_third_bidirectional_cm_intent = initialize_confusion_matrices(ATIS_lang)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ILW562mcwq5p","executionInfo":{"status":"ok","timestamp":1675093548858,"user_tz":-60,"elapsed":5531,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"74f14faa-303e-4df6-ec8c-7536fe699162","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]}],"source":["ATIS_Thirdmodel = AttentionModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","ATIS_Thirdmodel.apply(init_weights)\n","\n","ATIS_optimizer = optim.Adam(ATIS_Thirdmodel.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"N7cqODWt2A69","executionInfo":{"status":"ok","timestamp":1675093775765,"user_tz":-60,"elapsed":226912,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"1008cdb1-164e-49ea-adb6-70d7dd730ac6","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":[" 55%|█████▍    | 109/199 [00:57<00:47,  1.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","1  run\n","Intent Acc  0.952 \n","Slot F1 0.94 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 52%|█████▏    | 104/199 [00:49<00:45,  2.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","2  run\n","Intent Acc  0.946 \n","Slot F1 0.944 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 42%|████▏     | 84/199 [00:39<00:54,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","3  run\n","Intent Acc  0.946 \n","Slot F1 0.942 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▍     | 89/199 [00:42<00:51,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","4  run\n","Intent Acc  0.945 \n","Slot F1 0.945 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 79/199 [00:37<00:56,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","5  run\n","Intent Acc  0.953 \n","Slot F1 0.942 \n","\n","=========================================================================================\n","=========================================================================================\n","\n","Slot F1  0.943 +- 0.002\n","Intent Accuracy  0.948 +- 0.003\n","=========================================================================================\n"]}],"source":["ATIS_slots_f1s, ATIS_intents_acc = [], []\n","ATIS_intent_test_list_third_bidirectional, ATIS_results_test_list_third_bidirectional = [], []\n","for i in range(5):\n","  criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)#.to(device)\n","  criterion_intents = nn.CrossEntropyLoss()#.to(device)\n","  #ATIS_Firstmodel = ModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","  ATIS_Thirdmodel.apply(init_weights)\n","  ATIS_results_test, ATIS_intents_test, ATIS_sampled_epochs, ATIS_losses_train, ATIS_losses_dev, cm_atis_third_bidirectional_slot, cm_atis_third_bidirectional_intent = train_model_third_bidirectional(ATIS_dev_loader,\n","                                                                                                                                        ATIS_train_loader, \n","                                                                                                                                        ATIS_test_loader, \n","                                                                                                                                        ATIS_Thirdmodel,\n","                                                                                                                                        ATIS_lang, \n","                                                                                                                                        criterion_intents, \n","                                                                                                                                        criterion_slots, \n","                                                                                                                                        ATIS_optimizer)\n","\n","  ATIS_intents_acc.append(ATIS_intents_test['accuracy'])\n","  ATIS_slots_f1s.append(ATIS_results_test['total']['f-measure'])\n","  ATIS_intent_test_list_third_bidirectional.append(ATIS_intents_test)\n","  ATIS_results_test_list_third_bidirectional.append(ATIS_results_test)\n","\n","  ATIS_third_bidirectional_cm_slot += cm_atis_third_bidirectional_slot\n","  ATIS_third_bidirectional_cm_intent += cm_atis_third_bidirectional_intent\n","\n","  print('='*89)\n","  print(i+1,\" run\")\n","  print(\"Intent Acc \",round(ATIS_intents_test['accuracy'],3),\"\\nSlot F1\",round(ATIS_results_test['total']['f-measure'],3),\"\\n\")\n","  print('='*89)\n","\n","ATIS_slots_mean = np.mean(ATIS_slots_f1s)\n","ATIS_slots_std = np.std(ATIS_slots_f1s)\n","ATIS_intents_mean = np.mean(ATIS_intents_acc)\n","ATIS_intents_std = np.std(ATIS_intents_acc)\n","\n","print('='*89)\n","print('\\nSlot F1 ', round(ATIS_slots_mean,3), '+-', round(ATIS_slots_std,3))\n","print('Intent Accuracy ', round(ATIS_intents_mean,3), '+-', round(ATIS_intents_std, 3))\n","print('='*89)"]},{"cell_type":"markdown","metadata":{"id":"upWAX8r__piY"},"source":["### SNIPS"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"_3SPrZ56J6_Q","executionInfo":{"status":"ok","timestamp":1675093775766,"user_tz":-60,"elapsed":25,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_third_bidirectional_cm_slot, SNIPS_third_bidirectional_cm_intent = initialize_confusion_matrices(SNIPS_lang)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"9tx_EnrlA8g6","executionInfo":{"status":"ok","timestamp":1675093775766,"user_tz":-60,"elapsed":20,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"fa4fb9ff-7bf6-4db4-89c1-208ae8a8a608","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]}],"source":["SNIPS_Thirdmodel = AttentionModelIAS(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","SNIPS_Thirdmodel.apply(init_weights)\n","\n","SNIPS_optimizer = optim.Adam(SNIPS_Thirdmodel.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"z-Bkuu4s2CwP","executionInfo":{"status":"ok","timestamp":1675094139482,"user_tz":-60,"elapsed":363728,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"7e6a154d-8009-4888-cc97-2dd8a3c9029d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 79/199 [01:31<02:19,  1.16s/it]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","1  run\n","Intent Acc  0.967 \n","Slot F1 0.857 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 42%|████▏     | 84/199 [01:37<02:13,  1.16s/it]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","2  run\n","Intent Acc  0.967 \n","Slot F1 0.852 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 22%|██▏       | 44/199 [00:51<03:02,  1.18s/it]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","3  run\n","Intent Acc  0.964 \n","Slot F1 0.859 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 22%|██▏       | 44/199 [00:52<03:04,  1.19s/it]\n"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","4  run\n","Intent Acc  0.971 \n","Slot F1 0.849 \n","\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|██▉       | 59/199 [01:09<02:45,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","5  run\n","Intent Acc  0.97 \n","Slot F1 0.863 \n","\n","=========================================================================================\n","=========================================================================================\n","\n","Slot F1  0.856 +- 0.005\n","Intent Accuracy  0.968 +- 0.002\n","=========================================================================================\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["SNIPS_slots_f1s, SNIPS_intents_acc = [], []\n","SNIPS_intent_test_list_third_bidirectional, SNIPS_results_test_list_third_bidirectional = [], []\n","for i in range(5):\n","  criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)#.to(device)\n","  criterion_intents = nn.CrossEntropyLoss()#.to(device)\n","  #ATIS_Firstmodel = ModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n","  SNIPS_Thirdmodel.apply(init_weights)\n","  SNIPS_results_test, SNIPS_intents_test, SNIPS_sampled_epochs, SNIPS_losses_train, SNIPS_losses_dev, cm_slot_third_bidirectional_snips, cm_intent_third_bidirectional_snips = train_model_third_bidirectional(SNIPS_dev_loader,\n","                                                                                                                                        SNIPS_train_loader, \n","                                                                                                                                        SNIPS_test_loader, \n","                                                                                                                                        SNIPS_Thirdmodel,\n","                                                                                                                                        SNIPS_lang, \n","                                                                                                                                        criterion_intents, \n","                                                                                                                                        criterion_slots, \n","                                                                                                                                        SNIPS_optimizer)\n","\n","  SNIPS_intents_acc.append(SNIPS_intents_test['accuracy'])\n","  SNIPS_slots_f1s.append(SNIPS_results_test['total']['f-measure'])\n","  SNIPS_intent_test_list_third_bidirectional.append(SNIPS_intents_test)\n","  SNIPS_results_test_list_third_bidirectional.append(SNIPS_results_test)\n","\n","  SNIPS_third_bidirectional_cm_slot += cm_slot_third_bidirectional_snips\n","  SNIPS_third_bidirectional_cm_intent += cm_intent_third_bidirectional_snips\n","\n","  print('='*89)\n","  print(i+1,\" run\")\n","  print(\"Intent Acc \",round(SNIPS_intents_test['accuracy'],3),\"\\nSlot F1\",round(SNIPS_results_test['total']['f-measure'],3),\"\\n\")\n","  print('='*89)\n","\n","SNIPS_slots_mean = np.mean(SNIPS_slots_f1s)\n","SNIPS_slots_std = np.std(SNIPS_slots_f1s)\n","SNIPS_intents_mean = np.mean(SNIPS_intents_acc)\n","SNIPS_intents_std = np.std(SNIPS_intents_acc)\n","\n","print('='*89)\n","print('\\nSlot F1 ', round(SNIPS_slots_mean,3), '+-', round(SNIPS_slots_std,3))\n","print('Intent Accuracy ', round(SNIPS_intents_mean,3), '+-', round(SNIPS_intents_std, 3))\n","print('='*89)"]},{"cell_type":"markdown","metadata":{"id":"g0svEqxXFf7u"},"source":["# Tables"]},{"cell_type":"markdown","metadata":{"id":"2y9EIHGQBVlg"},"source":["## Creating the table"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"unpQ6AIaBYu9","executionInfo":{"status":"ok","timestamp":1675084580695,"user_tz":-60,"elapsed":66,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"1c38fbb2-5537-4e3b-8993-6271548809d0","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:  0.9417693169092946\n"]}],"source":["ATIS_first_accuracy_intent = ATIS_intent_test_list_first[0].pop('accuracy')\n","print(\"Accuracy: \", ATIS_first_accuracy_intent)"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"6GhXx6O53W57","executionInfo":{"status":"ok","timestamp":1675084580695,"user_tz":-60,"elapsed":63,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"2ca6420b-0db8-4cf9-f24b-b085833d925f","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:  0.9496080627099664\n"]}],"source":["ATIS_second_accuracy_intent = ATIS_intent_test_list_second[0].pop('accuracy')\n","print(\"Accuracy: \", ATIS_second_accuracy_intent)"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"UW_tbW6wMlkP","executionInfo":{"status":"ok","timestamp":1675084580695,"user_tz":-60,"elapsed":61,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"60a2be86-a74b-4acf-bfcb-074adcb05569","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:  0.948488241881299\n"]}],"source":["ATIS_third_monodirectional_accuracy_intent = ATIS_intent_test_list_third_monodirectional[0].pop('accuracy')\n","print(\"Accuracy: \", ATIS_third_monodirectional_accuracy_intent)"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"Xte3LI4fHEax","executionInfo":{"status":"ok","timestamp":1675084580696,"user_tz":-60,"elapsed":61,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"501f7e2f-ed39-45e9-c8e2-36b26099f17d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:  0.948488241881299\n"]}],"source":["ATIS_third_bidirectional_accuracy_intent = ATIS_intent_test_list_third_bidirectional[0].pop('accuracy')\n","print(\"Accuracy: \", ATIS_third_bidirectional_accuracy_intent)"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"qj4kAQrxBhxq","executionInfo":{"status":"ok","timestamp":1675084580696,"user_tz":-60,"elapsed":60,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"492604f2-edd3-4f7f-fc7e-1c5419ab9596","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:  0.9485714285714286\n"]}],"source":["SNIPS_first_accuracy_intent = SNIPS_intent_test_list_first[0].pop('accuracy')\n","print(\"Accuracy: \", SNIPS_first_accuracy_intent)"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"iKic7TBk3bIg","executionInfo":{"status":"ok","timestamp":1675084580696,"user_tz":-60,"elapsed":59,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"2a889624-c687-4a4f-ffaf-f72d85be3fb5","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:  0.9657142857142857\n"]}],"source":["SNIPS_second_accuracy_intent = SNIPS_intent_test_list_second[0].pop('accuracy')\n","print(\"Accuracy: \", SNIPS_second_accuracy_intent)"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"oJAbl0TAMvJo","executionInfo":{"status":"ok","timestamp":1675084580697,"user_tz":-60,"elapsed":59,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"3223a36f-b253-484d-ba4f-ecc112b61662","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:  0.9671428571428572\n"]}],"source":["SNIPS_third_bidirectional_accuracy_intent = SNIPS_intent_test_list_third_bidirectional[0].pop('accuracy')\n","print(\"Accuracy: \", SNIPS_third_bidirectional_accuracy_intent)"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"kW-A_NNhHd2z","executionInfo":{"status":"ok","timestamp":1675084580697,"user_tz":-60,"elapsed":58,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"9db264cf-3c79-4543-b437-0cc39a64eb2a","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:  0.9628571428571429\n"]}],"source":["SNIPS_third_monodirectional_accuracy_intent = SNIPS_intent_test_list_third_monodirectional[0].pop('accuracy')\n","print(\"Accuracy: \", SNIPS_third_monodirectional_accuracy_intent)"]},{"cell_type":"markdown","metadata":{"id":"r7FhMcpdLnF4"},"source":["## First Model"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"x5BQHZywrcHE","executionInfo":{"status":"ok","timestamp":1675084580697,"user_tz":-60,"elapsed":57,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_x_first = ATIS_intent_test_list_first[0]\n","ATIS_first_sorted_x_best_intent = sorted(ATIS_x_first.items(), key=lambda item: item[1]['f1-score'], reverse=True)\n","ATIS_first_best_intent = {key: value for key, value in ATIS_first_sorted_x_best_intent}\n","ATIS_table_best_first_intent = pd.DataFrame(ATIS_first_best_intent).transpose().head(20)\n","ATIS_table_best_first_intent = ATIS_table_best_first_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"RFVma51IrfDI","executionInfo":{"status":"ok","timestamp":1675084580697,"user_tz":-60,"elapsed":57,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_first_sorted_x_worst_intent = sorted(ATIS_x_first.items(), key=lambda item: item[1]['f1-score'], reverse=False)\n","ATIS_first_worst_intent = {key: value for key, value in ATIS_first_sorted_x_worst_intent}\n","ATIS_table_worst_first_intent = pd.DataFrame(ATIS_first_worst_intent).transpose().head(20)\n","ATIS_table_worst_first_intent = ATIS_table_worst_first_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"-LbWBP5EKPPR","executionInfo":{"status":"ok","timestamp":1675084580698,"user_tz":-60,"elapsed":57,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"4ea1cef3-40a3-4abf-a1ff-5a71cbcc89f5","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                precision  recall  f1-score  support\n"," abbreviation        1.000   1.000     1.000     33.0\n"," distance            1.000   1.000     1.000     10.0\n"," airline             0.974   1.000     0.987     38.0\n"," ground_service      0.947   1.000     0.973     36.0\n"," flight              0.946   0.992     0.968    632.0\n"," airfare             0.922   0.979     0.949     48.0\n"," capacity            0.950   0.905     0.927     21.0\n"," weighted avg        0.921   0.942     0.925    893.0\n"," airport             1.000   0.833     0.909     18.0\n"," ground_fare         1.000   0.714     0.833      7.0\n"," aircraft            0.857   0.667     0.750      9.0\n"," flight_time         0.500   1.000     0.667      1.0\n"," quantity            0.375   1.000     0.545      3.0\n"," macro avg           0.574   0.559     0.533    893.0\n"," flight+airfare      1.000   0.083     0.154     12.0\n"," airfare+flight      0.000   0.000     0.000      1.0\n"," city                0.000   0.000     0.000      6.0\n"," day_name            0.000   0.000     0.000      2.0\n"," flight+airline      0.000   0.000     0.000      1.0\n"," flight_no           0.000   0.000     0.000      8.0,\n","                    precision  recall  f1-score  support\n"," airfare+flight         0.000   0.000     0.000      1.0\n"," city                   0.000   0.000     0.000      6.0\n"," day_name               0.000   0.000     0.000      2.0\n"," flight+airline         0.000   0.000     0.000      1.0\n"," flight_no              0.000   0.000     0.000      8.0\n"," flight_no+airline      0.000   0.000     0.000      1.0\n"," meal                   0.000   0.000     0.000      6.0\n"," flight+airfare         1.000   0.083     0.154     12.0\n"," macro avg              0.574   0.559     0.533    893.0\n"," quantity               0.375   1.000     0.545      3.0\n"," flight_time            0.500   1.000     0.667      1.0\n"," aircraft               0.857   0.667     0.750      9.0\n"," ground_fare            1.000   0.714     0.833      7.0\n"," airport                1.000   0.833     0.909     18.0\n"," weighted avg           0.921   0.942     0.925    893.0\n"," capacity               0.950   0.905     0.927     21.0\n"," airfare                0.922   0.979     0.949     48.0\n"," flight                 0.946   0.992     0.968    632.0\n"," ground_service         0.947   1.000     0.973     36.0\n"," airline                0.974   1.000     0.987     38.0)"]},"metadata":{},"execution_count":84}],"source":["ATIS_table_best_first_intent, ATIS_table_worst_first_intent"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"yOWfE1P0rhbn","executionInfo":{"status":"ok","timestamp":1675084580698,"user_tz":-60,"elapsed":56,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_y_first = ATIS_results_test_list_first[0]\n","ATIS_first_sorted_y_best_results = sorted(ATIS_y_first.items(), key=lambda item: item[1]['f-measure'], reverse=True)\n","ATIS_first_best_results = dict(ATIS_first_sorted_y_best_results)\n","ATIS_table_best_first_results = pd.DataFrame.from_dict(ATIS_first_best_results).transpose()\n","ATIS_table_best_first_results = ATIS_table_best_first_results[:20]\n","ATIS_table_best_first_results = ATIS_table_best_first_results.round(decimals=3)"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"HOYxJkZfmBHO","executionInfo":{"status":"ok","timestamp":1675084580698,"user_tz":-60,"elapsed":56,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_first_sorted_y_worst_results = sorted(ATIS_y_first.items(), key=lambda item: item[1]['f-measure'], reverse=False)\n","ATIS_first_worst_results = dict(ATIS_first_sorted_y_worst_results)\n","ATIS_table_worst_first_results = pd.DataFrame.from_dict(ATIS_first_worst_results).transpose()\n","ATIS_table_worst_first_results = ATIS_table_worst_first_results[:20]\n","ATIS_table_worst_first_results = ATIS_table_worst_first_results.round(decimals=3)"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"sIfA88VSK8DW","executionInfo":{"status":"ok","timestamp":1675084580698,"user_tz":-60,"elapsed":55,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"629d40e5-341a-41e2-da17-bb6dbb226492","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                           precision  recall  f-measure  support\n"," state_code                     1.000   1.000      1.000      1.0\n"," connect                        1.000   1.000      1.000      6.0\n"," toloc.country_name             1.000   1.000      1.000      1.0\n"," fromloc.state_code             1.000   1.000      1.000     23.0\n"," economy                        1.000   1.000      1.000      6.0\n"," flight_days                    1.000   1.000      1.000     10.0\n"," toloc.state_code               1.000   1.000      1.000     18.0\n"," flight_stop                    1.000   1.000      1.000     21.0\n"," depart_date.day_name           0.995   0.981      0.988    212.0\n"," cost_relative                  1.000   0.973      0.986     37.0\n"," round_trip                     0.986   0.986      0.986     73.0\n"," depart_time.time_relative      0.984   0.969      0.977     65.0\n"," fromloc.city_name              0.971   0.983      0.977    704.0\n"," toloc.city_name                0.953   0.996      0.974    716.0\n"," meal                           0.941   1.000      0.970     16.0\n"," depart_date.month_name         0.981   0.946      0.964     56.0\n"," airline_name                   0.934   0.980      0.957    101.0\n"," meal_description               1.000   0.900      0.947     10.0\n"," transport_type                 1.000   0.900      0.947     10.0\n"," fromloc.state_name             0.941   0.941      0.941     17.0,\n","                            precision  recall  f-measure  support\n"," meal_code                      1.000   0.000      0.000      1.0\n"," fare_amount                    0.000   0.000      0.000      2.0\n"," mod                            1.000   0.000      0.000      2.0\n"," flight                         1.000   0.000      0.000      1.0\n"," compartment                    1.000   0.000      0.000      1.0\n"," state_name                     1.000   0.000      0.000      9.0\n"," return_date.date_relative      0.000   0.000      0.000      3.0\n"," airport_code                   0.000   0.000      0.000      9.0\n"," depart_time.end_time           0.000   0.000      0.000      3.0\n"," depart_date.year               1.000   0.000      0.000      3.0\n"," stoploc.airport_code           1.000   0.000      0.000      1.0\n"," days_code                      1.000   0.000      0.000      1.0\n"," arrive_date.date_relative      1.000   0.000      0.000      2.0\n"," return_date.day_name           1.000   0.000      0.000      2.0\n"," booking_class                  1.000   0.000      0.000      1.0\n"," fromloc.airport_name           0.148   0.333      0.205     12.0\n"," airport_name                   0.357   0.238      0.286     21.0\n"," restriction_code               0.333   0.250      0.286      4.0\n"," toloc.airport_name             0.333   0.333      0.333      3.0\n"," arrive_date.day_number         0.400   0.333      0.364      6.0)"]},"metadata":{},"execution_count":87}],"source":["ATIS_table_best_first_results, ATIS_table_worst_first_results"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"z6uMsqsQ6bAM","executionInfo":{"status":"ok","timestamp":1675084580699,"user_tz":-60,"elapsed":55,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_x_first = SNIPS_intent_test_list_first[0]\n","SNIPS_first_sorted_x_best_intent = sorted(SNIPS_x_first.items(), key=lambda item: item[1]['f1-score'], reverse=True)\n","SNIPS_first_best_intent = {key: value for key, value in SNIPS_first_sorted_x_best_intent}\n","SNIPS_table_best_first_intent = pd.DataFrame(SNIPS_first_best_intent).transpose().head(20)\n","SNIPS_table_best_first_intent = SNIPS_table_best_first_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"rQhzSypFrA1U","executionInfo":{"status":"ok","timestamp":1675084580699,"user_tz":-60,"elapsed":54,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_first_sorted_x_worst_intent = sorted(SNIPS_x_first.items(), key=lambda item: item[1]['f1-score'], reverse=False)\n","SNIPS_first_worst_intent = {key: value for key, value in SNIPS_first_sorted_x_worst_intent}\n","SNIPS_table_worst_first_intent = pd.DataFrame(SNIPS_first_worst_intent).transpose().head(20)\n","SNIPS_table_worst_first_intent = SNIPS_table_worst_first_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"v90qq6WwLDdn","executionInfo":{"status":"ok","timestamp":1675084580699,"user_tz":-60,"elapsed":53,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"815deaaa-c34f-4227-e6b7-e64be4561bdb","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                      precision  recall  f1-score  support\n"," AddToPlaylist             0.992   0.976     0.984    124.0\n"," RateBook                  0.987   0.962     0.975     80.0\n"," BookRestaurant            0.968   0.978     0.973     92.0\n"," GetWeather                0.962   0.981     0.971    104.0\n"," PlayMusic                 0.923   0.977     0.949     86.0\n"," macro avg                 0.949   0.950     0.949    700.0\n"," weighted avg              0.949   0.949     0.948    700.0\n"," SearchScreeningEvent      0.885   0.935     0.909    107.0\n"," SearchCreativeWork        0.928   0.841     0.882    107.0,\n","                       precision  recall  f1-score  support\n"," SearchCreativeWork        0.928   0.841     0.882    107.0\n"," SearchScreeningEvent      0.885   0.935     0.909    107.0\n"," weighted avg              0.949   0.949     0.948    700.0\n"," macro avg                 0.949   0.950     0.949    700.0\n"," PlayMusic                 0.923   0.977     0.949     86.0\n"," GetWeather                0.962   0.981     0.971    104.0\n"," BookRestaurant            0.968   0.978     0.973     92.0\n"," RateBook                  0.987   0.962     0.975     80.0\n"," AddToPlaylist             0.992   0.976     0.984    124.0)"]},"metadata":{},"execution_count":90}],"source":["SNIPS_table_best_first_intent, SNIPS_table_worst_first_intent"]},{"cell_type":"code","execution_count":91,"metadata":{"id":"NkWmdqDX6thJ","executionInfo":{"status":"ok","timestamp":1675084580700,"user_tz":-60,"elapsed":54,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_y_first = SNIPS_results_test_list_first[0]\n","SNIPS_first_sorted_y_best_results = sorted(SNIPS_y_first.items(), key=lambda item: item[1]['f-measure'], reverse=True)\n","SNIPS_first_best_results = dict(SNIPS_first_sorted_y_best_results)\n","SNIPS_table_best_first_results = pd.DataFrame.from_dict(SNIPS_first_best_results).transpose()\n","SNIPS_table_best_first_results = SNIPS_table_best_first_results[:20]\n","SNIPS_table_best_first_results = SNIPS_table_best_first_results.round(decimals=3)"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"iob_qiXY7DF5","executionInfo":{"status":"ok","timestamp":1675084580700,"user_tz":-60,"elapsed":53,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_first_sorted_y_worst_results = sorted(SNIPS_y_first.items(), key=lambda item: item[1]['f-measure'], reverse=False)\n","SNIPS_first_worst_results = dict(SNIPS_first_sorted_y_worst_results)\n","SNIPS_table_worst_first_results = pd.DataFrame.from_dict(SNIPS_first_worst_results).transpose()\n","SNIPS_table_worst_first_results = SNIPS_table_worst_first_results[:20]\n","SNIPS_table_worst_first_results = SNIPS_table_worst_first_results.round(decimals=3)"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"v4jUdKOFLKfd","executionInfo":{"status":"ok","timestamp":1675084580700,"user_tz":-60,"elapsed":53,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"f26e636d-76c9-4dc2-dc82-0ea8a1c7da28","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                       precision  recall  f-measure  support\n"," facility                   1.000   1.000      1.000      3.0\n"," movie_type                 1.000   1.000      1.000     33.0\n"," rating_unit                1.000   1.000      1.000     40.0\n"," best_rating                1.000   0.977      0.988     43.0\n"," condition_description      0.966   1.000      0.982     28.0\n"," condition_temperature      1.000   0.957      0.978     23.0\n"," restaurant_type            0.984   0.969      0.977     65.0\n"," rating_value               0.987   0.962      0.975     80.0\n"," music_item                 0.971   0.962      0.966    104.0\n"," current_location           1.000   0.929      0.963     14.0\n"," service                    0.958   0.958      0.958     24.0\n"," party_size_number          0.909   1.000      0.952     50.0\n"," object_type                0.945   0.957      0.951    162.0\n"," object_select              0.889   1.000      0.941     40.0\n"," location_name              0.920   0.958      0.939     24.0\n"," sort                       0.865   1.000      0.928     32.0\n"," year                       0.917   0.917      0.917     24.0\n"," playlist_owner             0.901   0.914      0.908     70.0\n"," object_location_type       0.840   0.955      0.894     22.0\n"," spatial_relation           0.844   0.915      0.878     71.0,\n","                             precision  recall  f-measure  support\n"," geographic_poi                  0.000   0.000      0.000     11.0\n"," track                           0.074   0.222      0.111      9.0\n"," album                           0.133   0.200      0.160     10.0\n"," entity_name                     0.414   0.364      0.387     33.0\n"," city                            0.500   0.383      0.434     60.0\n"," poi                             0.417   0.625      0.500      8.0\n"," object_name                     0.488   0.558      0.521    147.0\n"," restaurant_name                 0.533   0.533      0.533     15.0\n"," movie_name                      0.456   0.660      0.539     47.0\n"," country                         0.436   0.773      0.557     44.0\n"," genre                           0.444   0.800      0.571      5.0\n"," party_size_description          0.583   0.700      0.636     10.0\n"," timeRange                       0.636   0.785      0.703    107.0\n"," served_dish                     0.625   0.833      0.714     12.0\n"," cuisine                         0.818   0.643      0.720     14.0\n"," artist                          0.698   0.757      0.726    107.0\n"," total                           0.756   0.826      0.789   1790.0\n"," playlist                        0.766   0.837      0.800    129.0\n"," object_part_of_series_type      0.769   0.909      0.833     11.0\n"," state                           0.879   0.864      0.872     59.0)"]},"metadata":{},"execution_count":93}],"source":["SNIPS_table_best_first_results, SNIPS_table_worst_first_results"]},{"cell_type":"markdown","metadata":{"id":"q-ReDs0WLsr-"},"source":["## Second model"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"Bxzeopvlf5wq","executionInfo":{"status":"ok","timestamp":1675084580700,"user_tz":-60,"elapsed":52,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_x_second = ATIS_intent_test_list_second[0]\n","ATIS_second_sorted_x_best_intent = sorted(ATIS_x_second.items(), key=lambda item: item[1]['f1-score'], reverse=True)\n","ATIS_second_best_intent = {key: value for key, value in ATIS_second_sorted_x_best_intent}\n","ATIS_table_best_second_intent = pd.DataFrame(ATIS_second_best_intent).transpose().head(20)\n","ATIS_table_best_second_intent = ATIS_table_best_second_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"2rThwjRVgNtN","executionInfo":{"status":"ok","timestamp":1675084580701,"user_tz":-60,"elapsed":52,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_second_sorted_x_worst_intent = sorted(ATIS_x_second.items(), key=lambda item: item[1]['f1-score'], reverse=False)\n","ATIS_second_worst_intent = {key: value for key, value in ATIS_second_sorted_x_worst_intent}\n","ATIS_table_worst_second_intent = pd.DataFrame(ATIS_second_worst_intent).transpose().head(20)\n","ATIS_table_worst_second_intent = ATIS_table_worst_second_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":96,"metadata":{"id":"3AvY1GcEL04s","executionInfo":{"status":"ok","timestamp":1675084580701,"user_tz":-60,"elapsed":52,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"3b6098fe-fcb7-480e-f4f4-4115d2c65f57","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                precision  recall  f1-score  support\n"," abbreviation        1.000   1.000     1.000     33.0\n"," flight_time         1.000   1.000     1.000      1.0\n"," ground_service      0.973   1.000     0.986     36.0\n"," flight              0.956   0.989     0.972    632.0\n"," airport             1.000   0.944     0.971     18.0\n"," capacity            0.952   0.952     0.952     21.0\n"," airline             0.905   1.000     0.950     38.0\n"," airfare             0.922   0.979     0.949     48.0\n"," aircraft            1.000   0.889     0.941      9.0\n"," weighted avg        0.933   0.950     0.938    893.0\n"," distance            1.000   0.800     0.889     10.0\n"," ground_fare         1.000   0.714     0.833      7.0\n"," macro avg           0.648   0.601     0.605    893.0\n"," quantity            0.429   1.000     0.600      3.0\n"," flight+airfare      0.833   0.417     0.556     12.0\n"," city                1.000   0.333     0.500      6.0\n"," airfare+flight      0.000   0.000     0.000      1.0\n"," day_name            0.000   0.000     0.000      2.0\n"," flight+airline      0.000   0.000     0.000      1.0\n"," flight_no           0.000   0.000     0.000      8.0,\n","                    precision  recall  f1-score  support\n"," airfare+flight         0.000   0.000     0.000      1.0\n"," day_name               0.000   0.000     0.000      2.0\n"," flight+airline         0.000   0.000     0.000      1.0\n"," flight_no              0.000   0.000     0.000      8.0\n"," flight_no+airline      0.000   0.000     0.000      1.0\n"," meal                   0.000   0.000     0.000      6.0\n"," city                   1.000   0.333     0.500      6.0\n"," flight+airfare         0.833   0.417     0.556     12.0\n"," quantity               0.429   1.000     0.600      3.0\n"," macro avg              0.648   0.601     0.605    893.0\n"," ground_fare            1.000   0.714     0.833      7.0\n"," distance               1.000   0.800     0.889     10.0\n"," weighted avg           0.933   0.950     0.938    893.0\n"," aircraft               1.000   0.889     0.941      9.0\n"," airfare                0.922   0.979     0.949     48.0\n"," airline                0.905   1.000     0.950     38.0\n"," capacity               0.952   0.952     0.952     21.0\n"," airport                1.000   0.944     0.971     18.0\n"," flight                 0.956   0.989     0.972    632.0\n"," ground_service         0.973   1.000     0.986     36.0)"]},"metadata":{},"execution_count":96}],"source":["ATIS_table_best_second_intent, ATIS_table_worst_second_intent"]},{"cell_type":"code","execution_count":97,"metadata":{"id":"4iX2jF4fmhXQ","executionInfo":{"status":"ok","timestamp":1675084580701,"user_tz":-60,"elapsed":51,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_y_second = ATIS_results_test_list_second[0]\n","ATIS_second_sorted_y_best_results = sorted(ATIS_y_second.items(), key=lambda item: item[1]['f-measure'], reverse=True)\n","ATIS_second_best_results = dict(ATIS_second_sorted_y_best_results)\n","ATIS_table_best_second_results = pd.DataFrame.from_dict(ATIS_second_best_results).transpose()\n","ATIS_table_best_second_results = ATIS_table_best_second_results[:20]\n","ATIS_table_best_second_results = ATIS_table_best_second_results.round(decimals=3)"]},{"cell_type":"code","execution_count":98,"metadata":{"id":"U9HyOC7TppeL","executionInfo":{"status":"ok","timestamp":1675084580701,"user_tz":-60,"elapsed":51,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_second_sorted_y_worst_results = sorted(ATIS_y_second.items(), key=lambda item: item[1]['f-measure'], reverse=False)\n","ATIS_second_worst_results = dict(ATIS_second_sorted_y_worst_results)\n","ATIS_table_worst_second_results = pd.DataFrame.from_dict(ATIS_second_worst_results).transpose()\n","ATIS_table_worst_second_results = ATIS_table_worst_second_results[:20]\n","ATIS_table_worst_second_results = ATIS_table_worst_second_results.round(decimals=3)"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"aRDeU0CdL5o3","executionInfo":{"status":"ok","timestamp":1675084580702,"user_tz":-60,"elapsed":51,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"8604b187-c375-4437-e94b-19c067ce559a","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                           precision  recall  f-measure  support\n"," state_code                     1.000   1.000      1.000      1.0\n"," flight_time                    1.000   1.000      1.000      1.0\n"," connect                        1.000   1.000      1.000      6.0\n"," depart_time.start_time         1.000   1.000      1.000      3.0\n"," fromloc.state_code             1.000   1.000      1.000     23.0\n"," economy                        1.000   1.000      1.000      6.0\n"," depart_time.period_mod         1.000   1.000      1.000      5.0\n"," fromloc.airport_code           1.000   1.000      1.000      5.0\n"," flight_days                    1.000   1.000      1.000     10.0\n"," arrive_date.date_relative      1.000   1.000      1.000      2.0\n"," toloc.state_code               1.000   1.000      1.000     18.0\n"," flight_stop                    1.000   1.000      1.000     21.0\n"," depart_date.day_name           0.991   0.986      0.988    212.0\n"," cost_relative                  1.000   0.973      0.986     37.0\n"," round_trip                     1.000   0.973      0.986     73.0\n"," fromloc.city_name              0.979   0.993      0.986    704.0\n"," toloc.city_name                0.967   0.996      0.981    716.0\n"," class_type                     0.960   1.000      0.980     24.0\n"," depart_date.date_relative      0.944   1.000      0.971     17.0\n"," depart_time.time_relative      0.969   0.954      0.961     65.0,\n","                            precision  recall  f-measure  support\n"," meal_code                      1.000   0.000      0.000      1.0\n"," fare_amount                    0.000   0.000      0.000      2.0\n"," flight                         1.000   0.000      0.000      1.0\n"," compartment                    1.000   0.000      0.000      1.0\n"," toloc.country_name             1.000   0.000      0.000      1.0\n"," state_name                     1.000   0.000      0.000      9.0\n"," return_date.date_relative      0.000   0.000      0.000      3.0\n"," airport_code                   1.000   0.000      0.000      9.0\n"," depart_date.year               1.000   0.000      0.000      3.0\n"," stoploc.airport_code           1.000   0.000      0.000      1.0\n"," days_code                      1.000   0.000      0.000      1.0\n"," return_date.day_name           1.000   0.000      0.000      2.0\n"," booking_class                  1.000   0.000      0.000      1.0\n"," toloc.airport_name             0.333   0.333      0.333      3.0\n"," airport_name                   0.500   0.286      0.364     21.0\n"," toloc.airport_code             1.000   0.250      0.400      4.0\n"," fromloc.airport_name           0.370   0.833      0.513     12.0\n"," restriction_code               0.667   0.500      0.571      4.0\n"," aircraft_code                  0.933   0.424      0.583     33.0\n"," flight_number                  0.538   0.636      0.583     11.0)"]},"metadata":{},"execution_count":99}],"source":["ATIS_table_best_second_results, ATIS_table_worst_second_results"]},{"cell_type":"code","execution_count":100,"metadata":{"id":"Wyyx3yXuxYaX","executionInfo":{"status":"ok","timestamp":1675084580702,"user_tz":-60,"elapsed":50,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_x_second = SNIPS_intent_test_list_second[0]\n","SNIPS_second_sorted_x_best_intent = sorted(SNIPS_x_second.items(), key=lambda item: item[1]['f1-score'], reverse=True)\n","SNIPS_second_best_intent = {key: value for key, value in SNIPS_second_sorted_x_best_intent}\n","SNIPS_table_best_second_intent = pd.DataFrame(SNIPS_second_best_intent).transpose().head(20)\n","SNIPS_table_best_second_intent = SNIPS_table_best_second_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"Rn2vbf9BxcOW","executionInfo":{"status":"ok","timestamp":1675084580702,"user_tz":-60,"elapsed":50,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_second_sorted_x_worst_intent = sorted(SNIPS_x_second.items(), key=lambda item: item[1]['f1-score'], reverse=False)\n","SNIPS_second_worst_intent = {key: value for key, value in SNIPS_second_sorted_x_worst_intent}\n","SNIPS_table_worst_second_intent = pd.DataFrame(SNIPS_second_worst_intent).transpose().head(20)\n","SNIPS_table_worst_second_intent = SNIPS_table_worst_second_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"h9AxoBvCL9UU","executionInfo":{"status":"ok","timestamp":1675084580702,"user_tz":-60,"elapsed":49,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"5baca903-074f-4952-ba37-f04e5afe09a4","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                      precision  recall  f1-score  support\n"," AddToPlaylist             0.992   0.992     0.992    124.0\n"," RateBook                  0.987   0.975     0.981     80.0\n"," GetWeather                0.990   0.971     0.981    104.0\n"," BookRestaurant            0.968   0.978     0.973     92.0\n"," weighted avg              0.967   0.966     0.966    700.0\n"," macro avg                 0.966   0.966     0.966    700.0\n"," PlayMusic                 0.924   0.988     0.955     86.0\n"," SearchScreeningEvent      0.980   0.916     0.947    107.0\n"," SearchCreativeWork        0.918   0.944     0.931    107.0,\n","                       precision  recall  f1-score  support\n"," SearchCreativeWork        0.918   0.944     0.931    107.0\n"," SearchScreeningEvent      0.980   0.916     0.947    107.0\n"," PlayMusic                 0.924   0.988     0.955     86.0\n"," macro avg                 0.966   0.966     0.966    700.0\n"," weighted avg              0.967   0.966     0.966    700.0\n"," BookRestaurant            0.968   0.978     0.973     92.0\n"," GetWeather                0.990   0.971     0.981    104.0\n"," RateBook                  0.987   0.975     0.981     80.0\n"," AddToPlaylist             0.992   0.992     0.992    124.0)"]},"metadata":{},"execution_count":102}],"source":["SNIPS_table_best_second_intent, SNIPS_table_worst_second_intent"]},{"cell_type":"code","execution_count":103,"metadata":{"id":"PLbLpWShxgFa","executionInfo":{"status":"ok","timestamp":1675084580703,"user_tz":-60,"elapsed":49,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_y_second = SNIPS_results_test_list_second[0]\n","SNIPS_second_sorted_y_best_results = sorted(SNIPS_y_second.items(), key=lambda item: item[1]['f-measure'], reverse=True)\n","SNIPS_second_best_results = dict(SNIPS_second_sorted_y_best_results)\n","SNIPS_table_best_second_results = pd.DataFrame.from_dict(SNIPS_second_best_results).transpose()\n","SNIPS_table_best_second_results = SNIPS_table_best_second_results[:20]\n","SNIPS_table_best_second_results = SNIPS_table_best_second_results.round(decimals=3)"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"bqBTJEKzxjCz","executionInfo":{"status":"ok","timestamp":1675084580703,"user_tz":-60,"elapsed":49,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_second_sorted_y_worst_results = sorted(SNIPS_y_second.items(), key=lambda item: item[1]['f-measure'], reverse=False)\n","SNIPS_second_worst_results = dict(SNIPS_second_sorted_y_worst_results)\n","SNIPS_table_worst_second_results = pd.DataFrame.from_dict(SNIPS_second_worst_results).transpose()\n","SNIPS_table_worst_second_results = SNIPS_table_worst_second_results[:20]\n","SNIPS_table_worst_second_results = SNIPS_table_worst_second_results.round(decimals=3)"]},{"cell_type":"code","execution_count":105,"metadata":{"id":"nqsbSSblMAnO","executionInfo":{"status":"ok","timestamp":1675084580703,"user_tz":-60,"elapsed":48,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"085e7f8e-a4b2-4511-985d-c2d858c2e112","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                       precision  recall  f-measure  support\n"," playlist_owner             1.000   1.000      1.000     70.0\n"," service                    1.000   1.000      1.000     24.0\n"," condition_temperature      1.000   1.000      1.000     23.0\n"," facility                   1.000   1.000      1.000      3.0\n"," movie_type                 1.000   1.000      1.000     33.0\n"," rating_unit                1.000   1.000      1.000     40.0\n"," best_rating                1.000   1.000      1.000     43.0\n"," object_location_type       1.000   1.000      1.000     22.0\n"," restaurant_type            1.000   0.985      0.992     65.0\n"," party_size_number          1.000   0.980      0.990     50.0\n"," object_select              0.976   1.000      0.988     40.0\n"," rating_value               0.975   0.988      0.981     80.0\n"," location_name              1.000   0.958      0.979     24.0\n"," music_item                 0.954   1.000      0.977    104.0\n"," sort                       0.941   1.000      0.970     32.0\n"," condition_description      0.933   1.000      0.966     28.0\n"," object_type                0.957   0.969      0.963    162.0\n"," current_location           1.000   0.929      0.963     14.0\n"," state                      0.966   0.949      0.957     59.0\n"," geographic_poi             1.000   0.909      0.952     11.0,\n","                             precision  recall  f-measure  support\n"," track                           0.118   0.222      0.154      9.0\n"," album                           0.154   0.200      0.174     10.0\n"," entity_name                     0.500   0.576      0.535     33.0\n"," served_dish                     0.455   0.833      0.588     12.0\n"," poi                             0.625   0.625      0.625      8.0\n"," movie_name                      0.652   0.638      0.645     47.0\n"," restaurant_name                 0.611   0.733      0.667     15.0\n"," object_name                     0.625   0.714      0.667    147.0\n"," party_size_description          0.727   0.800      0.762     10.0\n"," artist                          0.738   0.869      0.798    107.0\n"," genre                           0.800   0.800      0.800      5.0\n"," object_part_of_series_type      0.833   0.909      0.870     11.0\n"," cuisine                         1.000   0.786      0.880     14.0\n"," playlist                        0.872   0.899      0.885    129.0\n"," total                           0.866   0.908      0.887   1790.0\n"," country                         0.927   0.864      0.894     44.0\n"," city                            0.875   0.933      0.903     60.0\n"," year                            0.828   1.000      0.906     24.0\n"," timeRange                       0.927   0.953      0.940    107.0\n"," spatial_relation                0.944   0.944      0.944     71.0)"]},"metadata":{},"execution_count":105}],"source":["SNIPS_table_best_second_results, SNIPS_table_worst_second_results"]},{"cell_type":"markdown","metadata":{"id":"bIakC-v1Nyr4"},"source":["## Third model"]},{"cell_type":"markdown","metadata":{"id":"bdtX7Ta-OD_z"},"source":["### Monodirectional"]},{"cell_type":"code","execution_count":106,"metadata":{"id":"hPjrNyJaN__Y","executionInfo":{"status":"ok","timestamp":1675084580703,"user_tz":-60,"elapsed":47,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_x_third_monodirectional = ATIS_intent_test_list_third_monodirectional[0]\n","ATIS_third_monodirectional_sorted_x_best_intent = sorted(ATIS_x_third_monodirectional.items(), key=lambda item: item[1]['f1-score'], reverse=True)\n","ATIS_third_monodirectional_best_intent = {key: value for key, value in ATIS_third_monodirectional_sorted_x_best_intent}\n","ATIS_table_best_third_monodirectional_intent = pd.DataFrame(ATIS_third_monodirectional_best_intent).transpose().head(20)\n","ATIS_table_best_third_monodirectional_intent = ATIS_table_best_third_monodirectional_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":107,"metadata":{"id":"No37XzTfN__a","executionInfo":{"status":"ok","timestamp":1675084580703,"user_tz":-60,"elapsed":46,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_third_monodirectional_sorted_x_worst_intent = sorted(ATIS_x_third_monodirectional.items(), key=lambda item: item[1]['f1-score'], reverse=False)\n","ATIS_third_monodirectional_worst_intent = {key: value for key, value in ATIS_third_monodirectional_sorted_x_worst_intent}\n","ATIS_table_worst_third_monodirectional_intent = pd.DataFrame(ATIS_third_monodirectional_worst_intent).transpose().head(20)\n","ATIS_table_worst_third_monodirectional_intent = ATIS_table_worst_third_monodirectional_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"zO2lRUi_N__b","executionInfo":{"status":"ok","timestamp":1675084580704,"user_tz":-60,"elapsed":46,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"f30d24a9-b8ac-4457-d367-d3b49b80b373","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                precision  recall  f1-score  support\n"," abbreviation        1.000   1.000     1.000     33.0\n"," flight_time         1.000   1.000     1.000      1.0\n"," ground_service      0.973   1.000     0.986     36.0\n"," flight              0.955   0.984     0.970    632.0\n"," airfare             0.959   0.979     0.969     48.0\n"," capacity            1.000   0.905     0.950     21.0\n"," airport             0.944   0.944     0.944     18.0\n"," weighted avg        0.947   0.948     0.941    893.0\n"," airline             0.881   0.974     0.925     38.0\n"," distance            1.000   0.800     0.889     10.0\n"," aircraft            0.889   0.889     0.889      9.0\n"," ground_fare         1.000   0.714     0.833      7.0\n"," city                1.000   0.500     0.667      6.0\n"," meal                1.000   0.500     0.667      6.0\n"," macro avg           0.737   0.632     0.644    893.0\n"," quantity            0.333   1.000     0.500      3.0\n"," flight+airfare      0.800   0.333     0.471     12.0\n"," flight_no           1.000   0.125     0.222      8.0\n"," airfare+flight      0.000   0.000     0.000      1.0\n"," day_name            0.000   0.000     0.000      2.0,\n","                    precision  recall  f1-score  support\n"," airfare+flight         0.000   0.000     0.000      1.0\n"," day_name               0.000   0.000     0.000      2.0\n"," flight+airline         0.000   0.000     0.000      1.0\n"," flight_no+airline      0.000   0.000     0.000      1.0\n"," flight_no              1.000   0.125     0.222      8.0\n"," flight+airfare         0.800   0.333     0.471     12.0\n"," quantity               0.333   1.000     0.500      3.0\n"," macro avg              0.737   0.632     0.644    893.0\n"," city                   1.000   0.500     0.667      6.0\n"," meal                   1.000   0.500     0.667      6.0\n"," ground_fare            1.000   0.714     0.833      7.0\n"," aircraft               0.889   0.889     0.889      9.0\n"," distance               1.000   0.800     0.889     10.0\n"," airline                0.881   0.974     0.925     38.0\n"," weighted avg           0.947   0.948     0.941    893.0\n"," airport                0.944   0.944     0.944     18.0\n"," capacity               1.000   0.905     0.950     21.0\n"," airfare                0.959   0.979     0.969     48.0\n"," flight                 0.955   0.984     0.970    632.0\n"," ground_service         0.973   1.000     0.986     36.0)"]},"metadata":{},"execution_count":108}],"source":["ATIS_table_best_third_monodirectional_intent, ATIS_table_worst_third_monodirectional_intent"]},{"cell_type":"code","execution_count":109,"metadata":{"id":"N6OlPOAeN__b","executionInfo":{"status":"ok","timestamp":1675084580704,"user_tz":-60,"elapsed":45,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_y_third_monodirectional = ATIS_results_test_list_third_monodirectional[0]\n","ATIS_third_monodirectional_sorted_y_best_results = sorted(ATIS_y_third_monodirectional.items(), key=lambda item: item[1]['f-measure'], reverse=True)\n","ATIS_third_monodirectional_best_results = dict(ATIS_third_monodirectional_sorted_y_best_results)\n","ATIS_table_best_third_monodirectional_results = pd.DataFrame.from_dict(ATIS_third_monodirectional_best_results).transpose()\n","ATIS_table_best_third_monodirectional_results = ATIS_table_best_third_monodirectional_results[:20]\n","ATIS_table_best_third_monodirectional_results = ATIS_table_best_third_monodirectional_results.round(decimals=3)"]},{"cell_type":"code","execution_count":110,"metadata":{"id":"9JwHEZb-N__c","executionInfo":{"status":"ok","timestamp":1675084580704,"user_tz":-60,"elapsed":44,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_third_monodirectional_sorted_y_worst_results = sorted(ATIS_y_third_monodirectional.items(), key=lambda item: item[1]['f-measure'], reverse=False)\n","ATIS_third_monodirectional_worst_results = dict(ATIS_third_monodirectional_sorted_y_worst_results)\n","ATIS_table_worst_third_monodirectional_results = pd.DataFrame.from_dict(ATIS_third_monodirectional_worst_results).transpose()\n","ATIS_table_worst_third_monodirectional_results = ATIS_table_worst_third_monodirectional_results[:20]\n","ATIS_table_worst_third_monodirectional_results = ATIS_table_worst_third_monodirectional_results.round(decimals=3)"]},{"cell_type":"code","execution_count":111,"metadata":{"id":"d-aU8X_GN__c","executionInfo":{"status":"ok","timestamp":1675084580704,"user_tz":-60,"elapsed":43,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"99e160a2-8690-48e9-e52f-13544212a6d4","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                           precision  recall  f-measure  support\n"," state_code                     1.000   1.000      1.000      1.0\n"," flight_time                    1.000   1.000      1.000      1.0\n"," connect                        1.000   1.000      1.000      6.0\n"," toloc.country_name             1.000   1.000      1.000      1.0\n"," fromloc.state_code             1.000   1.000      1.000     23.0\n"," economy                        1.000   1.000      1.000      6.0\n"," fromloc.airport_code           1.000   1.000      1.000      5.0\n"," flight_days                    1.000   1.000      1.000     10.0\n"," arrive_date.date_relative      1.000   1.000      1.000      2.0\n"," toloc.state_code               1.000   1.000      1.000     18.0\n"," flight_stop                    1.000   1.000      1.000     21.0\n"," depart_date.day_name           0.991   0.986      0.988    212.0\n"," cost_relative                  1.000   0.973      0.986     37.0\n"," round_trip                     1.000   0.973      0.986     73.0\n"," fromloc.city_name              0.976   0.990      0.983    704.0\n"," toloc.city_name                0.967   0.996      0.981    716.0\n"," airline_name                   0.980   0.980      0.980    101.0\n"," class_type                     0.960   1.000      0.980     24.0\n"," depart_date.month_name         0.965   0.982      0.973     56.0\n"," depart_date.date_relative      0.944   1.000      0.971     17.0,\n","                            precision  recall  f-measure  support\n"," meal_code                      1.000   0.000      0.000      1.0\n"," flight                         1.000   0.000      0.000      1.0\n"," compartment                    1.000   0.000      0.000      1.0\n"," state_name                     1.000   0.000      0.000      9.0\n"," stoploc.airport_code           1.000   0.000      0.000      1.0\n"," days_code                      1.000   0.000      0.000      1.0\n"," return_date.day_name           1.000   0.000      0.000      2.0\n"," booking_class                  1.000   0.000      0.000      1.0\n"," arrive_time.start_time         0.500   0.250      0.333      8.0\n"," period_of_day                  1.000   0.250      0.400      4.0\n"," return_date.date_relative      0.500   0.333      0.400      3.0\n"," day_name                       0.500   0.500      0.500      2.0\n"," fare_amount                    0.500   0.500      0.500      2.0\n"," depart_time.end_time           1.000   0.333      0.500      3.0\n"," depart_date.year               1.000   0.333      0.500      3.0\n"," airport_name                   0.727   0.381      0.500     21.0\n"," airport_code                   0.800   0.444      0.571      9.0\n"," restriction_code               0.667   0.500      0.571      4.0\n"," or                             0.429   1.000      0.600      3.0\n"," fromloc.airport_name           0.429   1.000      0.600     12.0)"]},"metadata":{},"execution_count":111}],"source":["ATIS_table_best_third_monodirectional_results, ATIS_table_worst_third_monodirectional_results"]},{"cell_type":"code","execution_count":112,"metadata":{"id":"IIAz7DlyN__c","executionInfo":{"status":"ok","timestamp":1675084580705,"user_tz":-60,"elapsed":43,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_x_third_monodirectional = SNIPS_intent_test_list_third_monodirectional[0]\n","SNIPS_third_monodirectional_sorted_x_best_intent = sorted(SNIPS_x_third_monodirectional.items(), key=lambda item: item[1]['f1-score'], reverse=True)\n","SNIPS_third_monodirectional_best_intent = {key: value for key, value in SNIPS_third_monodirectional_sorted_x_best_intent}\n","SNIPS_table_best_third_monodirectional_intent = pd.DataFrame(SNIPS_third_monodirectional_best_intent).transpose().head(20)\n","SNIPS_table_best_third_monodirectional_intent = SNIPS_table_best_third_monodirectional_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":113,"metadata":{"id":"y39Bq-KsN__d","executionInfo":{"status":"ok","timestamp":1675084580705,"user_tz":-60,"elapsed":42,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_third_monodirectional_sorted_x_worst_intent = sorted(SNIPS_x_third_monodirectional.items(), key=lambda item: item[1]['f1-score'], reverse=False)\n","SNIPS_third_monodirectional_worst_intent = {key: value for key, value in SNIPS_third_monodirectional_sorted_x_worst_intent}\n","SNIPS_table_worst_third_monodirectional_intent = pd.DataFrame(SNIPS_third_monodirectional_worst_intent).transpose().head(20)\n","SNIPS_table_worst_third_monodirectional_intent = SNIPS_table_worst_third_monodirectional_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":114,"metadata":{"id":"DuGZa3vBN__d","executionInfo":{"status":"ok","timestamp":1675084580705,"user_tz":-60,"elapsed":42,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"7c03d2f2-0d75-418f-ed81-ce939da5df07","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                      precision  recall  f1-score  support\n"," AddToPlaylist             0.992   0.984     0.988    124.0\n"," RateBook                  0.988   0.988     0.988     80.0\n"," GetWeather                0.963   0.990     0.976    104.0\n"," BookRestaurant            0.978   0.957     0.967     92.0\n"," weighted avg              0.964   0.963     0.963    700.0\n"," macro avg                 0.963   0.964     0.963    700.0\n"," SearchScreeningEvent      0.980   0.916     0.947    107.0\n"," PlayMusic                 0.904   0.988     0.944     86.0\n"," SearchCreativeWork        0.934   0.925     0.930    107.0,\n","                       precision  recall  f1-score  support\n"," SearchCreativeWork        0.934   0.925     0.930    107.0\n"," PlayMusic                 0.904   0.988     0.944     86.0\n"," SearchScreeningEvent      0.980   0.916     0.947    107.0\n"," macro avg                 0.963   0.964     0.963    700.0\n"," weighted avg              0.964   0.963     0.963    700.0\n"," BookRestaurant            0.978   0.957     0.967     92.0\n"," GetWeather                0.963   0.990     0.976    104.0\n"," RateBook                  0.988   0.988     0.988     80.0\n"," AddToPlaylist             0.992   0.984     0.988    124.0)"]},"metadata":{},"execution_count":114}],"source":["SNIPS_table_best_third_monodirectional_intent, SNIPS_table_worst_third_monodirectional_intent"]},{"cell_type":"code","execution_count":115,"metadata":{"id":"611uAvxzN__d","executionInfo":{"status":"ok","timestamp":1675084580705,"user_tz":-60,"elapsed":40,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_y_third_monodirectional = SNIPS_results_test_list_third_monodirectional[0]\n","SNIPS_third_monodirectional_sorted_y_best_results = sorted(SNIPS_y_third_monodirectional.items(), key=lambda item: item[1]['f-measure'], reverse=True)\n","SNIPS_third_monodirectional_best_results = dict(SNIPS_third_monodirectional_sorted_y_best_results)\n","SNIPS_table_best_third_monodirectional_results = pd.DataFrame.from_dict(SNIPS_third_monodirectional_best_results).transpose()\n","SNIPS_table_best_third_monodirectional_results = SNIPS_table_best_third_monodirectional_results[:20]\n","SNIPS_table_best_third_monodirectional_results = SNIPS_table_best_third_monodirectional_results.round(decimals=3)"]},{"cell_type":"code","execution_count":116,"metadata":{"id":"ju2-dmsON__e","executionInfo":{"status":"ok","timestamp":1675084580706,"user_tz":-60,"elapsed":41,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_third_monodirectional_sorted_y_worst_results = sorted(SNIPS_y_third_monodirectional.items(), key=lambda item: item[1]['f-measure'], reverse=False)\n","SNIPS_third_monodirectional_worst_results = dict(SNIPS_third_monodirectional_sorted_y_worst_results)\n","SNIPS_table_worst_third_monodirectional_results = pd.DataFrame.from_dict(SNIPS_third_monodirectional_worst_results).transpose()\n","SNIPS_table_worst_third_monodirectional_results = SNIPS_table_worst_third_monodirectional_results[:20]\n","SNIPS_table_worst_third_monodirectional_results = SNIPS_table_worst_third_monodirectional_results.round(decimals=3)"]},{"cell_type":"code","execution_count":117,"metadata":{"id":"47tDFrThN__f","executionInfo":{"status":"ok","timestamp":1675084580706,"user_tz":-60,"elapsed":40,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"2911dad6-0935-4e3f-a633-7721b9b2233a","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                       precision  recall  f-measure  support\n"," current_location           1.000   1.000      1.000     14.0\n"," location_name              1.000   1.000      1.000     24.0\n"," service                    1.000   1.000      1.000     24.0\n"," condition_temperature      1.000   1.000      1.000     23.0\n"," restaurant_type            1.000   1.000      1.000     65.0\n"," facility                   1.000   1.000      1.000      3.0\n"," movie_type                 1.000   1.000      1.000     33.0\n"," rating_unit                1.000   1.000      1.000     40.0\n"," best_rating                1.000   1.000      1.000     43.0\n"," object_select              1.000   1.000      1.000     40.0\n"," condition_description      1.000   1.000      1.000     28.0\n"," year                       1.000   1.000      1.000     24.0\n"," object_location_type       1.000   1.000      1.000     22.0\n"," playlist_owner             0.986   1.000      0.993     70.0\n"," rating_value               0.988   0.988      0.988     80.0\n"," music_item                 0.963   1.000      0.981    104.0\n"," party_size_number          0.961   0.980      0.970     50.0\n"," sort                       0.941   1.000      0.970     32.0\n"," state                      0.966   0.966      0.966     59.0\n"," object_type                0.957   0.957      0.957    162.0,\n","                             precision  recall  f-measure  support\n"," track                           0.067   0.111      0.083      9.0\n"," album                           0.273   0.300      0.286     10.0\n"," poi                             0.417   0.625      0.500      8.0\n"," entity_name                     0.588   0.606      0.597     33.0\n"," movie_name                      0.588   0.638      0.612     47.0\n"," restaurant_name                 0.588   0.667      0.625     15.0\n"," object_name                     0.603   0.714      0.654    147.0\n"," served_dish                     0.692   0.750      0.720     12.0\n"," genre                           0.667   0.800      0.727      5.0\n"," cuisine                         0.900   0.643      0.750     14.0\n"," artist                          0.691   0.879      0.774    107.0\n"," geographic_poi                  0.818   0.818      0.818     11.0\n"," party_size_description          0.750   0.900      0.818     10.0\n"," city                            0.815   0.883      0.848     60.0\n"," playlist                        0.827   0.891      0.858    129.0\n"," object_part_of_series_type      0.833   0.909      0.870     11.0\n"," total                           0.856   0.907      0.881   1790.0\n"," country                         0.929   0.886      0.907     44.0\n"," spatial_relation                0.852   0.972      0.908     71.0\n"," timeRange                       0.935   0.944      0.940    107.0)"]},"metadata":{},"execution_count":117}],"source":["SNIPS_table_best_third_monodirectional_results, SNIPS_table_worst_third_monodirectional_results"]},{"cell_type":"markdown","metadata":{"id":"PRfl7DnITBbU"},"source":["### Bidirectional"]},{"cell_type":"code","execution_count":118,"metadata":{"id":"AaQHw9knTHy-","executionInfo":{"status":"ok","timestamp":1675084580706,"user_tz":-60,"elapsed":39,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_x_third_bidirectional = ATIS_intent_test_list_third_bidirectional[0]\n","ATIS_third_bidirectional_sorted_x_best_intent = sorted(ATIS_x_third_bidirectional.items(), key=lambda item: item[1]['f1-score'], reverse=True)\n","ATIS_third_bidirectional_best_intent = {key: value for key, value in ATIS_third_bidirectional_sorted_x_best_intent}\n","ATIS_table_best_third_bidirectional_intent = pd.DataFrame(ATIS_third_bidirectional_best_intent).transpose().head(20)\n","ATIS_table_best_third_bidirectional_intent = ATIS_table_best_third_bidirectional_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":119,"metadata":{"id":"IPAhyhngTHy_","executionInfo":{"status":"ok","timestamp":1675084580706,"user_tz":-60,"elapsed":38,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_third_bidirectional_sorted_x_worst_intent = sorted(ATIS_x_third_bidirectional.items(), key=lambda item: item[1]['f1-score'], reverse=False)\n","ATIS_third_bidirectional_worst_intent = {key: value for key, value in ATIS_third_bidirectional_sorted_x_worst_intent}\n","ATIS_table_worst_third_bidirectional_intent = pd.DataFrame(ATIS_third_bidirectional_worst_intent).transpose().head(20)\n","ATIS_table_worst_third_bidirectional_intent = ATIS_table_worst_third_bidirectional_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":120,"metadata":{"id":"s5KSm7NHTHzA","executionInfo":{"status":"ok","timestamp":1675084580706,"user_tz":-60,"elapsed":38,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"8daf4856-f12e-46a4-af74-527c6e29b648","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                precision  recall  f1-score  support\n"," abbreviation        1.000   1.000     1.000     33.0\n"," flight_time         1.000   1.000     1.000      1.0\n"," ground_service      0.973   1.000     0.986     36.0\n"," capacity            1.000   0.952     0.976     21.0\n"," airport             1.000   0.944     0.971     18.0\n"," flight              0.947   0.992     0.969    632.0\n"," airline             0.973   0.947     0.960     38.0\n"," airfare             0.939   0.958     0.948     48.0\n"," aircraft            1.000   0.889     0.941      9.0\n"," weighted avg        0.947   0.948     0.940    893.0\n"," ground_fare         1.000   0.714     0.833      7.0\n"," city                1.000   0.500     0.667      6.0\n"," macro avg           0.750   0.611     0.637    893.0\n"," distance            1.000   0.400     0.571     10.0\n"," quantity            0.375   1.000     0.545      3.0\n"," meal                1.000   0.333     0.500      6.0\n"," flight+airfare      0.800   0.333     0.471     12.0\n"," flight_no           1.000   0.250     0.400      8.0\n"," airfare+flight      0.000   0.000     0.000      1.0\n"," day_name            0.000   0.000     0.000      2.0,\n","                    precision  recall  f1-score  support\n"," airfare+flight         0.000   0.000     0.000      1.0\n"," day_name               0.000   0.000     0.000      2.0\n"," flight+airline         0.000   0.000     0.000      1.0\n"," flight_no+airline      0.000   0.000     0.000      1.0\n"," flight_no              1.000   0.250     0.400      8.0\n"," flight+airfare         0.800   0.333     0.471     12.0\n"," meal                   1.000   0.333     0.500      6.0\n"," quantity               0.375   1.000     0.545      3.0\n"," distance               1.000   0.400     0.571     10.0\n"," macro avg              0.750   0.611     0.637    893.0\n"," city                   1.000   0.500     0.667      6.0\n"," ground_fare            1.000   0.714     0.833      7.0\n"," weighted avg           0.947   0.948     0.940    893.0\n"," aircraft               1.000   0.889     0.941      9.0\n"," airfare                0.939   0.958     0.948     48.0\n"," airline                0.973   0.947     0.960     38.0\n"," flight                 0.947   0.992     0.969    632.0\n"," airport                1.000   0.944     0.971     18.0\n"," capacity               1.000   0.952     0.976     21.0\n"," ground_service         0.973   1.000     0.986     36.0)"]},"metadata":{},"execution_count":120}],"source":["ATIS_table_best_third_bidirectional_intent, ATIS_table_worst_third_bidirectional_intent"]},{"cell_type":"code","execution_count":121,"metadata":{"id":"fCEfIzZZTHzB","executionInfo":{"status":"ok","timestamp":1675084580707,"user_tz":-60,"elapsed":38,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_y_third_bidirectional = ATIS_results_test_list_third_bidirectional[0]\n","ATIS_third_bidirectional_sorted_y_best_results = sorted(ATIS_y_third_bidirectional.items(), key=lambda item: item[1]['f-measure'], reverse=True)\n","ATIS_third_bidirectional_best_results = dict(ATIS_third_bidirectional_sorted_y_best_results)\n","ATIS_table_best_third_bidirectional_results = pd.DataFrame.from_dict(ATIS_third_bidirectional_best_results).transpose()\n","ATIS_table_best_third_bidirectional_results = ATIS_table_best_third_bidirectional_results[:20]\n","ATIS_table_best_third_bidirectional_results = ATIS_table_best_third_bidirectional_results.round(decimals=3)"]},{"cell_type":"code","execution_count":122,"metadata":{"id":"vKuRYEu5THzB","executionInfo":{"status":"ok","timestamp":1675084580707,"user_tz":-60,"elapsed":37,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["ATIS_third_bidirectional_sorted_y_worst_results = sorted(ATIS_y_third_bidirectional.items(), key=lambda item: item[1]['f-measure'], reverse=False)\n","ATIS_third_bidirectional_worst_results = dict(ATIS_third_bidirectional_sorted_y_worst_results)\n","ATIS_table_worst_third_bidirectional_results = pd.DataFrame.from_dict(ATIS_third_bidirectional_worst_results).transpose()\n","ATIS_table_worst_third_bidirectional_results = ATIS_table_worst_third_bidirectional_results[:20]\n","ATIS_table_worst_third_bidirectional_results = ATIS_table_worst_third_bidirectional_results.round(decimals=3)"]},{"cell_type":"code","execution_count":123,"metadata":{"id":"aeVoYtEfTHzB","executionInfo":{"status":"ok","timestamp":1675084580707,"user_tz":-60,"elapsed":36,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"897ac46f-d1ed-491d-c463-a387259a83e8","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                           precision  recall  f-measure  support\n"," state_code                     1.000   1.000      1.000      1.0\n"," flight_time                    1.000   1.000      1.000      1.0\n"," fare_amount                    1.000   1.000      1.000      2.0\n"," connect                        1.000   1.000      1.000      6.0\n"," toloc.country_name             1.000   1.000      1.000      1.0\n"," depart_time.start_time         1.000   1.000      1.000      3.0\n"," fromloc.state_code             1.000   1.000      1.000     23.0\n"," economy                        1.000   1.000      1.000      6.0\n"," toloc.airport_name             1.000   1.000      1.000      3.0\n"," depart_time.period_mod         1.000   1.000      1.000      5.0\n"," fromloc.airport_code           1.000   1.000      1.000      5.0\n"," flight_days                    1.000   1.000      1.000     10.0\n"," days_code                      1.000   1.000      1.000      1.0\n"," arrive_date.date_relative      1.000   1.000      1.000      2.0\n"," toloc.state_code               1.000   1.000      1.000     18.0\n"," flight_stop                    1.000   1.000      1.000     21.0\n"," depart_date.month_name         0.982   1.000      0.991     56.0\n"," depart_date.day_name           0.991   0.986      0.988    212.0\n"," cost_relative                  1.000   0.973      0.986     37.0\n"," round_trip                     1.000   0.973      0.986     73.0,\n","                            precision  recall  f-measure  support\n"," period_of_day                  1.000   0.000      0.000      4.0\n"," meal_code                      1.000   0.000      0.000      1.0\n"," flight                         1.000   0.000      0.000      1.0\n"," compartment                    1.000   0.000      0.000      1.0\n"," state_name                     1.000   0.000      0.000      9.0\n"," return_time.period_mod         0.000   0.000      0.000      0.0\n"," stoploc.airport_code           1.000   0.000      0.000      1.0\n"," return_date.day_name           1.000   0.000      0.000      2.0\n"," booking_class                  1.000   0.000      0.000      1.0\n"," return_date.date_relative      0.500   0.333      0.400      3.0\n"," depart_time.end_time           0.500   0.333      0.400      3.0\n"," airport_name                   0.636   0.333      0.437     21.0\n"," depart_date.year               1.000   0.333      0.500      3.0\n"," airport_code                   0.800   0.444      0.571      9.0\n"," restriction_code               0.667   0.500      0.571      4.0\n"," fromloc.airport_name           0.423   0.917      0.579     12.0\n"," city_name                      0.935   0.509      0.659     57.0\n"," day_name                       1.000   0.500      0.667      2.0\n"," mod                            1.000   0.500      0.667      2.0\n"," toloc.airport_code             1.000   0.500      0.667      4.0)"]},"metadata":{},"execution_count":123}],"source":["ATIS_table_best_third_bidirectional_results, ATIS_table_worst_third_bidirectional_results"]},{"cell_type":"code","execution_count":124,"metadata":{"id":"nW6KVMaTTHzC","executionInfo":{"status":"ok","timestamp":1675084580707,"user_tz":-60,"elapsed":35,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_x_third_bidirectional = SNIPS_intent_test_list_third_bidirectional[0]\n","SNIPS_third_bidirectional_sorted_x_best_intent = sorted(SNIPS_x_third_bidirectional.items(), key=lambda item: item[1]['f1-score'], reverse=True)\n","SNIPS_third_bidirectional_best_intent = {key: value for key, value in SNIPS_third_bidirectional_sorted_x_best_intent}\n","SNIPS_table_best_third_bidirectional_intent = pd.DataFrame(SNIPS_third_bidirectional_best_intent).transpose().head(20)\n","SNIPS_table_best_third_bidirectional_intent = SNIPS_table_best_third_bidirectional_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":125,"metadata":{"id":"tzpXG_5YTHzC","executionInfo":{"status":"ok","timestamp":1675084580708,"user_tz":-60,"elapsed":34,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_third_bidirectional_sorted_x_worst_intent = sorted(SNIPS_x_third_bidirectional.items(), key=lambda item: item[1]['f1-score'], reverse=False)\n","SNIPS_third_bidirectional_worst_intent = {key: value for key, value in SNIPS_third_bidirectional_sorted_x_worst_intent}\n","SNIPS_table_worst_third_bidirectional_intent = pd.DataFrame(SNIPS_third_bidirectional_worst_intent).transpose().head(20)\n","SNIPS_table_worst_third_bidirectional_intent = SNIPS_table_worst_third_bidirectional_intent.round(decimals=3)"]},{"cell_type":"code","execution_count":126,"metadata":{"id":"rt_avHgRTHzC","executionInfo":{"status":"ok","timestamp":1675084580708,"user_tz":-60,"elapsed":33,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"51937e4f-3d16-4ed9-f2c6-3176277767c1","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                      precision  recall  f1-score  support\n"," RateBook                  1.000   1.000     1.000     80.0\n"," AddToPlaylist             1.000   0.992     0.996    124.0\n"," BookRestaurant            0.978   0.989     0.984     92.0\n"," GetWeather                0.981   0.981     0.981    104.0\n"," macro avg                 0.969   0.968     0.968    700.0\n"," weighted avg              0.969   0.967     0.967    700.0\n"," PlayMusic                 0.965   0.953     0.959     86.0\n"," SearchScreeningEvent      0.980   0.897     0.937    107.0\n"," SearchCreativeWork        0.880   0.963     0.920    107.0,\n","                       precision  recall  f1-score  support\n"," SearchCreativeWork        0.880   0.963     0.920    107.0\n"," SearchScreeningEvent      0.980   0.897     0.937    107.0\n"," PlayMusic                 0.965   0.953     0.959     86.0\n"," weighted avg              0.969   0.967     0.967    700.0\n"," macro avg                 0.969   0.968     0.968    700.0\n"," GetWeather                0.981   0.981     0.981    104.0\n"," BookRestaurant            0.978   0.989     0.984     92.0\n"," AddToPlaylist             1.000   0.992     0.996    124.0\n"," RateBook                  1.000   1.000     1.000     80.0)"]},"metadata":{},"execution_count":126}],"source":["SNIPS_table_best_third_bidirectional_intent, SNIPS_table_worst_third_bidirectional_intent"]},{"cell_type":"code","execution_count":127,"metadata":{"id":"Z5zaWcAoTHzD","executionInfo":{"status":"ok","timestamp":1675084580708,"user_tz":-60,"elapsed":32,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_y_third_bidirectional = SNIPS_results_test_list_third_bidirectional[0]\n","SNIPS_third_bidirectional_sorted_y_best_results = sorted(SNIPS_y_third_bidirectional.items(), key=lambda item: item[1]['f-measure'], reverse=True)\n","SNIPS_third_bidirectional_best_results = dict(SNIPS_third_bidirectional_sorted_y_best_results)\n","SNIPS_table_best_third_bidirectional_results = pd.DataFrame.from_dict(SNIPS_third_bidirectional_best_results).transpose()\n","SNIPS_table_best_third_bidirectional_results = SNIPS_table_best_third_bidirectional_results[:20]\n","SNIPS_table_best_third_bidirectional_results = SNIPS_table_best_third_bidirectional_results.round(decimals=3)"]},{"cell_type":"code","execution_count":128,"metadata":{"id":"HvYJjM8ETHzD","executionInfo":{"status":"ok","timestamp":1675084580708,"user_tz":-60,"elapsed":31,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["SNIPS_third_bidirectional_sorted_y_worst_results = sorted(SNIPS_y_third_bidirectional.items(), key=lambda item: item[1]['f-measure'], reverse=False)\n","SNIPS_third_bidirectional_worst_results = dict(SNIPS_third_bidirectional_sorted_y_worst_results)\n","SNIPS_table_worst_third_bidirectional_results = pd.DataFrame.from_dict(SNIPS_third_bidirectional_worst_results).transpose()\n","SNIPS_table_worst_third_bidirectional_results = SNIPS_table_worst_third_bidirectional_results[:20]\n","SNIPS_table_worst_third_bidirectional_results = SNIPS_table_worst_third_bidirectional_results.round(decimals=3)"]},{"cell_type":"code","execution_count":129,"metadata":{"id":"IDN4mJ-1THzE","executionInfo":{"status":"ok","timestamp":1675084580709,"user_tz":-60,"elapsed":32,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"df11525c-c241-4c13-a218-ad49033e01a1","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                       precision  recall  f-measure  support\n"," condition_temperature      1.000   1.000      1.000     23.0\n"," restaurant_type            1.000   1.000      1.000     65.0\n"," facility                   1.000   1.000      1.000      3.0\n"," movie_type                 1.000   1.000      1.000     33.0\n"," rating_unit                1.000   1.000      1.000     40.0\n"," best_rating                1.000   1.000      1.000     43.0\n"," condition_description      1.000   1.000      1.000     28.0\n"," genre                      1.000   1.000      1.000      5.0\n"," object_location_type       1.000   1.000      1.000     22.0\n"," rating_value               0.988   1.000      0.994     80.0\n"," party_size_number          1.000   0.980      0.990     50.0\n"," playlist_owner             0.986   0.986      0.986     70.0\n"," sort                       0.970   1.000      0.985     32.0\n"," service                    1.000   0.958      0.979     24.0\n"," object_select              0.952   1.000      0.976     40.0\n"," music_item                 0.971   0.971      0.971    104.0\n"," current_location           1.000   0.929      0.963     14.0\n"," location_name              0.958   0.958      0.958     24.0\n"," object_type                0.951   0.963      0.957    162.0\n"," spatial_relation           0.919   0.958      0.938     71.0,\n","                             precision  recall  f-measure  support\n"," track                           0.048   0.111      0.067      9.0\n"," album                           0.062   0.100      0.077     10.0\n"," entity_name                     0.375   0.727      0.495     33.0\n"," poi                             0.455   0.625      0.526      8.0\n"," restaurant_name                 0.500   0.600      0.545     15.0\n"," movie_name                      0.571   0.596      0.583     47.0\n"," object_name                     0.593   0.714      0.648    147.0\n"," artist                          0.736   0.598      0.660    107.0\n"," served_dish                     0.667   0.833      0.741     12.0\n"," party_size_description          0.750   0.900      0.818     10.0\n"," cuisine                         1.000   0.714      0.833     14.0\n"," object_part_of_series_type      0.769   0.909      0.833     11.0\n"," city                            0.877   0.833      0.855     60.0\n"," playlist                        0.812   0.907      0.857    129.0\n"," timeRange                       0.794   0.935      0.858    107.0\n"," total                           0.835   0.886      0.860   1790.0\n"," country                         0.886   0.886      0.886     44.0\n"," geographic_poi                  0.909   0.909      0.909     11.0\n"," year                            0.917   0.917      0.917     24.0\n"," state                           0.918   0.949      0.933     59.0)"]},"metadata":{},"execution_count":129}],"source":["SNIPS_table_best_third_bidirectional_results, SNIPS_table_worst_third_bidirectional_results"]},{"cell_type":"markdown","metadata":{"id":"rlalmaJPlvvT"},"source":["# Confusion matrices"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"Z3Vum76xluVH","executionInfo":{"status":"ok","timestamp":1675095032683,"user_tz":-60,"elapsed":42,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"outputs":[],"source":["import matplotlib\n","\n","def plot_confusion_matrix(data, label=\"Confusion Matrix\"):\n","    plt.figure(figsize = (10,10))\n","    plt.title(label)\n","    plt.imshow(data, norm = matplotlib.colors.Normalize(vmin = 0, vmax = 255))\n","\n","def advance_plot_confusion_matrix(data, label=\"Confusion Matrix\"):\n","    plt.figure(figsize = (20,20))\n","    plt.title(label)\n","    plt.imshow(data, cmap = 'YlOrRd', norm = matplotlib.colors.Normalize(vmin = 0, vmax = 255))\n","    plt.colorbar()\n","    plt.grid(visible=True)\n","    for i in range(len(data)):\n","        for j in range(len(data)):\n","            plt.text(j, i, data[i][j], ha=\"center\", va=\"center\", color=\"black\")\n"]},{"cell_type":"markdown","metadata":{"id":"ixjePtdemDjO"},"source":["### First model"]},{"cell_type":"code","source":["plot_confusion_matrix(ATIS_first_cm_intent, label=\"Intents\")\n","plot_confusion_matrix(ATIS_first_cm_slot, label=\"Slots\")"],"metadata":{"id":"4LlwjnYoo4kY","executionInfo":{"status":"error","timestamp":1675095032684,"user_tz":-60,"elapsed":38,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"ca87ed4f-bf95-47db-d6c6-e6948190b9cb","colab":{"base_uri":"https://localhost:8080/","height":224}},"execution_count":32,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-1675c4af9a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mATIS_first_cm_intent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Intents\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mATIS_first_cm_slot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Slots\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'ATIS_first_cm_intent' is not defined"]}]},{"cell_type":"code","source":["plot_confusion_matrix(SNIPS_first_cm_intent, label=\"Intents\")\n","plot_confusion_matrix(SNIPS_first_cm_slot, label=\"Slots\")"],"metadata":{"id":"xyQCLM9Qo4ki","executionInfo":{"status":"aborted","timestamp":1675095032685,"user_tz":-60,"elapsed":31,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ztLmjPL9mhE9"},"source":["### Second model"]},{"cell_type":"code","source":["plot_confusion_matrix(ATIS_second_cm_intent, label=\"Intents\")\n","plot_confusion_matrix(ATIS_second_cm_slot, label=\"Slots\")"],"metadata":{"id":"xvUtcbsMmWpH","executionInfo":{"status":"ok","timestamp":1675095041170,"user_tz":-60,"elapsed":1878,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"95d33ae7-3fce-41e6-c47b-7e58f8c27ed5","colab":{"base_uri":"https://localhost:8080/","height":1000}},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAkcAAAJOCAYAAAC9TKM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdTklEQVR4nO3de7BlZXkn4N873dBGE25qMTZNIikxlnEiYiuITspIMqBhxD8sg5OZQWKKylScmMtEIc6UNTWTipapeCkTpxhvZMpCLWJGyph0UEnlohAabG/gpQuDNA1CRNDRGQTyzR9nW7zndLd0n73P2efyPFXU3t+3197rPatW1/nxrfesXWOMAACw4J/NuwAAgLVEOAIAaIQjAIBGOAIAaIQjAIBGOAIAaIQjYM2rqldU1d/Ouw5gcxCOgDWjqp5XVZ+sqvuq6p6q+ruqetYRfsZfVdUvr1SNwMa3dd4FACRJVR2T5CNJ/kOSDyY5Osm/THL/POsCNh8rR8Ba8eQkGWNcMcZ4aIzxf8cYfznG+OzSDavqrKq6frLCdH1VnTWZ/90sBKq3V9X/qaq314I3V9VdVfWtqvpcVT1tdX80YD0RjoC14stJHqqqy6vqhVV1/ME2qqoTkvxZkrcleWySP0jyZ1X12DHG65L8TZJXjTF+eIzxqiT/KslPZyF8HZvkZUm+sfI/DrBeCUfAmjDG+FaS5yUZSf5nkrur6qqqOnHJpj+f5CtjjP81xnhwjHFFki8m+deH+OgHkvxIkqckqTHGzWOMO1bmpwA2AuEIWDMmweUVY4wdSZ6WZHuStyzZbHuSW5fM3ZrkpEN85ieSvD3JHya5q6oum/Q3ARyUcASsSWOMLyZ5bxZCUrc/yY8tmfvRJLd//60H+ay3jTGemeSpWbi89tszLRbYUIQjYE2oqqdU1W9V1Y7J+OQkL09y7ZJNP5rkyVX1b6pqa1X9QhZCz0cmr389yY+3z31WVZ1RVUcl+U6S/5fkn1b4xwHWMeEIWCu+neSMJNdV1XeyEIo+n+S3+kZjjG8kOW8y/40kr0ly3hjjHyebvDXJS6vqm1X1tiTHZKGH6ZtZuPz2jSRvWvkfB1ivaowDVqABADYtK0cAAI1wBADQCEcAAM2KhaOqOreqvlRVe6vqkpXaDwDALK1IQ3ZVbcnCVwH8XJJ9Sa5P8vIxxk0H2/7o2jYelcfMvA4AgEP5dr75j2OMxy+d37pC+3t2kr1jjFuSpKren+T8JAcNR4/KY3JGnb1CpQAAHOhj48qld9tPsnKX1U5Kclsb78uSW/tX1cVVtbuqdj+Q+1eoDACAIzO3huwxxmVjjJ1jjJ1HZdu8ygAAWGSlwtHtSU5u4x15+HuPAADWrJUKR9cnObWqTqmqo5NckOSqFdoXAMDMrEhD9hjjwap6VZJdSbYkefcY4wsrsS8AgFlaqb9Wyxjjo1n49mwAgHXDHbIBABrhCACgEY4AABrhCACgEY4AABrhCACgEY4AABrhCACgEY4AABrhCACgEY4AABrhCACgEY4AAJqt8y5gpezav2fR+Jztp82pEgBgPbFyBADQCEcAAI1wBADQbNieIz1GAMByWDkCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCAZsN+8ews7Nq/Z9HYl9kCwMZn5QgAoBGOAAAa4QgAoNFz9AMs7THSgwQAG5+VIwCARjgCAGiEIwCARs/REdBjBAAbn5UjAIBGOAIAaIQjAIBGOAIAaIQjAIBGOAIAaIQjAIBGOAIAaIQjAIBGOAIAaIQjAIBGOAIAaIQjAIBGOAIAaIQjAIBGOAIAaLbOu4DN7h/++3MWjZ/4nz81p0rYbLb8xJMWjR/60t45VQKwtlg5AgBohCMAgEY4AgBo9BzNmR4j5kWPEcDBWTkCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCARjgCAGjc52idefAFz1w03vqJG+ZUCcD68dUrnr5ofMrLPzPzfTz0M6cvGm+55saZ74PVYeUIAKARjgAAGuEIAKDRc7TOLO0x2rV/zwHbnLP9tNUqB1jPzvypA+eu/ezq17EKVqLHaKlZ9BhtPXnHovGDt+2b+jM5claOAAAa4QgAoBGOAACaZYejqjq5qq6pqpuq6gtV9erJ/AlVdXVVfWXyePzsygUAWFk1xljeG6uekOQJY4wbq+pHktyQ5CVJXpHknjHGG6rqkiTHjzFe+4M+65g6YZxRZy+rDgCA5fjYuPKGMcbOpfPLXjkaY9wxxrhx8vzbSW5OclKS85NcPtns8iwEJgCAdWEmf8pfVU9M8owk1yU5cYxxx+SlO5OceIj3XJzk4iR5VB49izIAAKY2dUN2Vf1wkj9J8utjjG/118bCNbuDXrcbY1w2xtg5xth5VLZNWwYAwExMtXJUVUdlIRi9b4zxocn016vqCWOMOyZ9SXdNWyTTWXqjSDeJBIBDm+av1SrJu5LcPMb4g/bSVUkunDy/MMmHl18eAMDqmmbl6LlJ/l2Sz1XV95cmfifJG5J8sKpemeTWJC+brkQAgNWz7HA0xvjbJHWIl/1dPgCwLvni2U1AjxEAHD5fHwIA0AhHAACNcAQA0Og5wn2QAKCxcgQA0AhHAACNcAQA0Og5Qo8RADRWjgAAGuEIAKARjgAAGuEIAKARjgAAGuEIAKARjgAAGuEIAKARjgAAGuEIAKARjgAAGuEIAKDxxbPMxJmfeWDR+NqnHzWnSgBgOlaOAAAa4QgAoBGOAAAaPUfMhB4jADYKK0cAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQbJ13AbBcu/bvWTQ+Z/tpc6oEgI3EyhEAQCMcAQA0whEAQKPniHVraY/Re7/2twds84offd5qlQMcwkM/c/qi8ZZrbpxTJXB4rBwBADTCEQBAIxwBADTCEQBAoyGbDUPzNaxNGrBZb6wcAQA0whEAQCMcAQA0whEAQCMcAQA0whEAQCMcAQA07nPETOy79KxF4x2/98k5VXJkdu3fs2i89MtsAdh8rBwBADTCEQBAIxwBADR6jpiJ9dJjtJQeIwCWsnIEANAIRwAAjXAEANBMHY6qaktVfbqqPjIZn1JV11XV3qr6QFUdPX2ZAACrYxYrR69OcnMbvzHJm8cYT0ryzSSvnME+AABWxVThqKp2JPn5JO+cjCvJC5JcOdnk8iQvmWYfAACradqVo7ckeU2Sf5qMH5vk3jHGg5PxviQnHeyNVXVxVe2uqt0P5P4pywAAmI1lh6OqOi/JXWOMG5bz/jHGZWOMnWOMnUdl23LLAACYqWluAvncJC+uqhcleVSSY5K8NclxVbV1snq0I8nt05cJALA6lr1yNMa4dIyxY4zxxCQXJPnEGOMXk1yT5KWTzS5M8uGpqwQAWCUrcZ+j1yb5zaram4UepHetwD4AAFbETL5bbYzxV0n+avL8liTPnsXnAgCsNnfIBgBohCMAgEY4AgBohCMAgEY4AgBohCMAgEY4AgBohCMAgEY4AgBohCMAgEY4AgBohCMAgEY4AgBohCMAgEY4AgBohCMAgEY4AgBohCMAgEY4AgBohCMAgEY4AgBohCMAgEY4AgBohCMAgEY4AgBots67AOCRffsXzlw0/pEPXDunSgA2PitHAACNcAQA0AhHAACNniNYB/QYAaweK0cAAI1wBADQCEcAAI2eI9gAvvyeZy4aP/miG+ZUCcD6Z+UIAKARjgAAGuEIAKDRcwQbgB4jgNmxcgQA0AhHAACNcAQA0AhHAACNcAQA0AhHAACNcAQA0AhHAACNm0DCJrVr/55F43O2nzanSljL7rnoOYvGJ7znU3OqBFaPlSMAgEY4AgBohCMAgEbPEWxSeow4HHqM2IysHAEANMIRAEAjHAEANMIRAEAjHAEANMIRAEAjHAEANMIRAEAjHAEANMIRAEAjHAEANMIRAEAjHAEANMIRAEAjHAEANMIRAECzdd4FABvHrv17Fo3P2X7anCoBWD4rRwAAjXAEANAIRwAAjZ4jYGb0GAEbgZUjAIBGOAIAaKYKR1V1XFVdWVVfrKqbq+o5VXVCVV1dVV+ZPB4/q2IBAFbatCtHb03yF2OMpyR5epKbk1yS5ONjjFOTfHwyBgBYF5Ydjqrq2CQ/neRdSTLG+N4Y494k5ye5fLLZ5UleMm2RAACrZZqVo1OS3J3kPVX16ap6Z1U9JsmJY4w7JtvcmeTEg725qi6uqt1VtfuB3D9FGQAAszNNONqa5PQk7xhjPCPJd7LkEtoYYyQZB3vzGOOyMcbOMcbOo7JtijIAAGZnmnC0L8m+McZ1k/GVWQhLX6+qJyTJ5PGu6UoEAFg9yw5HY4w7k9xWVT8xmTo7yU1Jrkpy4WTuwiQfnqpCAIBVNO0dsv9jkvdV1dFJbklyURYC1wer6pVJbk3ysin3AQCwaqYKR2OMPUl2HuSls6f5XACAeXGHbACARjgCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCARjgCAGiEIwCAZuu8CwBmb+vJOw6Ye/C2fXOoZP527d9zwNw520+bQyVrj/MEDs7KEQBAIxwBADTCEQBAIxwBADQasmED0lT7MM3Xh+Y8gYOzcgQA0AhHAACNcAQA0Og5AtikvvyeZx4w9+SLbphDJbC2WDkCAGiEIwCARjgCAGj0HAFsUvqL4OCsHAEANMIRAEAjHAEANMIRAEAjHAEANMIRAEAjHAEANMIRAEAjHAEANMIRAEAjHAEANMIRAEAjHAEANMIRAEAjHAEANMIRAECzdd4FAGxEu/bvWTQ+Z/tpc6oEOFJWjgAAGuEIAKARjgAAGj1HACtAjxGsX1aOAAAa4QgAoBGOAAAaPUcAm9SX3/PMA+aefNENc6gE1hYrRwAAjXAEANAIRwAAjZ4jgE1KfxEcnJUjAIBGOAIAaIQjAIBGOAIAaIQjAIBGOAIAaIQjAIBGOAIAaIQjAIBGOAIAaIQjAIBmqnBUVb9RVV+oqs9X1RVV9aiqOqWqrquqvVX1gao6elbFAgCstGWHo6o6KcmvJdk5xnhaki1JLkjyxiRvHmM8Kck3k7xyFoUCAKyGaS+rbU3yQ1W1Ncmjk9yR5AVJrpy8fnmSl0y5DwCAVbPscDTGuD3J7yf5WhZC0X1Jbkhy7xjjwclm+5KcdLD3V9XFVbW7qnY/kPuXWwYAwExNc1nt+CTnJzklyfYkj0ly7uG+f4xx2Rhj5xhj51HZttwyAABmaprLaj+b5KtjjLvHGA8k+VCS5yY5bnKZLUl2JLl9yhoBAFbNNOHoa0nOrKpHV1UlOTvJTUmuSfLSyTYXJvnwdCUCAKyeaXqOrstC4/WNST43+azLkrw2yW9W1d4kj03yrhnUCQCwKrY+8iaHNsZ4fZLXL5m+Jcmzp/lcAIB5cYdsAIBGOAIAaIQjAIBGOAIAaIQjAIBGOAIAaIQjAIBGOAIAaKa6CeRmU8/6F4vG4/rPrXoNW3/s5EXjB2+9berPXAs/FxzKluOOXTR+6N775lTJxrNr/54D5s7ZftocKtkYtjz+8YvGD91995wqYVpWjgAAGuEIAKARjgAAGuEIAKCpMca8a8gxdcI4o86edxkAwCbysXHlDWOMnUvnrRwBADTCEQBAIxwBADRuAgnAIS29UaSbRLIZWDkCAGiEIwCARjgCAGj0HAFwSHqM2IysHAEANMIRAEAjHAEANHqOAFi2W974nEXjH3/tp+ZUyQ+25bEnLBo/9I175lQJ64GVIwCARjgCAGiEIwCARs8RAMu2tMdo6XexJWvjXkmr0WM0nrv456y/O/BYsD5YOQIAaIQjAIBGOAIAaIQjAIBGQzYAM3Ow5uszP/PAovG1Tz9qtcpZVRqwNw4rRwAAjXAEANAIRwAAjZ4jAFbURu0xYuOycgQA0AhHAACNcAQA0AhHAACNcAQA0AhHAACNcAQA0AhHAACNcAQA0AhHAACNcAQA0AhHAACNcAQA0AhHAACNcAQA0AhHAADN1nkXAABH6r6PPmnR+NgX7Z1TJWxEVo4AABrhCACgEY4AABo9RwCsO3qMWElWjgAAGuEIAKARjgAAGuEIAKARjgAAGuEIAKARjgAAGvc5AmDD27V/z6LxOdtPm/k+thx37KLxQ/feN/N9sDqsHAEANMIRAEAjHAEANHqOANjwVqLHaCk9RhuHlSMAgEY4AgBoHjEcVdW7q+quqvp8mzuhqq6uqq9MHo+fzFdVva2q9lbVZ6vq9JUsHgBg1g6n5+i9Sd6e5I/b3CVJPj7GeENVXTIZvzbJC5OcOvnvjCTvmDwCa8zjP3ncovHdZ907p0pg/pbeBylZnT4l1qZHXDkaY/x1knuWTJ+f5PLJ88uTvKTN//FYcG2S46rqCbMqFgBgpS235+jEMcYdk+d3Jjlx8vykJLe17fZN5g5QVRdX1e6q2v1A7l9mGQAAszV1Q/YYYyQZy3jfZWOMnWOMnUdl27RlAADMxHLD0de/f7ls8njXZP72JCe37XZM5gAA1oXl3gTyqiQXJnnD5PHDbf5VVfX+LDRi39cuvwFriAZseJjma7pHDEdVdUWS5yd5XFXtS/L6LISiD1bVK5PcmuRlk80/muRFSfYm+W6Si1agZgCAFfOI4WiM8fJDvHT2QbYdSX512qIAAObFHbIBABpfPAsAh+Ef/ttzFo2f+F8+NadKWGlWjgAAGuEIAKARjgAAGj1HAJvU/S961gFz2z56/RwqWR+W9hjd/SuLe5Ae/z/0IG0UVo4AABrhCACgEY4AABo9RwCb1GbqL3rjV69bNH7tKWdM/ZlLe4x27d+zaOz72tYvK0cAAI1wBADQCEcAAI2eIwA2vFn0GD0SPUYbh5UjAIBGOAIAaIQjAIBGOAIAaDRkA8AqOfMzDywaX/v0o+ZUCT+IlSMAgEY4AgBohCMAgEbPEWxS3ztn56Lx0bt2z6kSmL+Hfub0A+a2XHPjzPeztMfozl8/a9H4n7/lkzPfJ0fOyhEAQCMcAQA0whEAQFNjjHnXkGPqhHFGnT3vMgCATeRj48obxhg7l85bOQIAaIQjAIBGOAIAaIQjAIBGOAIAaIQjAIBGOAIAaHy3GgCsE/suXfxdbDt+z3exrQQrRwAAjXAEANAIRwAAjZ4jAFgnlvYY7dq/54Btztl+2mqVs2FZOQIAaIQjAIBGOAIAaIQjAIBGQzab2pbjjl00fuje++ZUCay+ped/snn/DazXY3Gw5uulTdoatI+clSMAgEY4AgBohCMAgEbPEZvaeugpgJXi/H/YRjoWeoymZ+UIAKARjgAAGuEIAKARjgAAGuEIAKARjgAAGuEIAKBxnyMA2MT2XXrWovGO3/vknCpZO6wcAQA0whEAQCMcAQA0eo4AYBPTY3QgK0cAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAI1wBADQCEcAAM0jhqOqendV3VVVn29zb6qqL1bVZ6vqT6vquPbapVW1t6q+VFXnrFThAAAr4XBWjt6b5Nwlc1cnedoY46eSfDnJpUlSVU9NckGSn5y854+qasvMqgUAWGGPGI7GGH+d5J4lc385xnhwMrw2yY7J8/OTvH+Mcf8Y46tJ9iZ59gzrBQBYUbPoOfqlJH8+eX5Sktvaa/smcweoqourandV7X4g98+gDACA6U0VjqrqdUkeTPK+I33vGOOyMcbOMcbOo7JtmjIAAGZm63LfWFWvSHJekrPHGGMyfXuSk9tmOyZzAADrwrJWjqrq3CSvSfLiMcZ320tXJbmgqrZV1SlJTk3y99OXCQCwOh5x5aiqrkjy/CSPq6p9SV6fhb9O25bk6qpKkmvHGL8yxvhCVX0wyU1ZuNz2q2OMh1aqeACAWauHr4jNzzF1wjijzp53GQDAJvKxceUNY4ydS+fdIRsAoFl2QzYAbBT3ffRJB8wd+6K9c6iEtcDKEQBAIxwBADTCEQBAo+cIgE1PfxGdlSMAgEY4AgBohCMAgEY4AgBohCMAgEY4AgBohCMAgMZ9jgCANW//b5+1aLz9TZ9csX1ZOQIAaIQjAIBGOAIAaPQcAQBr3kr2GC1l5QgAoBGOAAAa4QgAoBGOAAAa4QgAoBGOAAAa4QgAoBGOAAAa4QgAoBGOAAAa4QgAoBGOAAAa4QgAoBGOAAAa4QgAoBGOAACaGmPMu4ZU1d1Jbk3yuCT/OOdyNhLHc7Ycz9lxLGfL8Zwdx3K21vrx/LExxuOXTq6JcPR9VbV7jLFz3nVsFI7nbDmes+NYzpbjOTuO5Wyt1+PpshoAQCMcAQA0ay0cXTbvAjYYx3O2HM/ZcSxny/GcHcdyttbl8VxTPUcAAPO21laOAADmSjgCAGjWTDiqqnOr6ktVtbeqLpl3PetJVZ1cVddU1U1V9YWqevVk/oSqurqqvjJ5PH7eta4nVbWlqj5dVR+ZjE+pqusm5+gHquroede4XlTVcVV1ZVV9sapurqrnOD+Xp6p+Y/Lv/PNVdUVVPcq5efiq6t1VdVdVfb7NHfRcrAVvmxzXz1bV6fOrfG06xPF80+Tf+mer6k+r6rj22qWT4/mlqjpnPlU/sjURjqpqS5I/TPLCJE9N8vKqeup8q1pXHkzyW2OMpyY5M8mvTo7fJUk+PsY4NcnHJ2MO36uT3NzGb0zy5jHGk5J8M8kr51LV+vTWJH8xxnhKkqdn4bg6P49QVZ2U5NeS7BxjPC3JliQXxLl5JN6b5Nwlc4c6F1+Y5NTJfxcneccq1bievDcHHs+rkzxtjPFTSb6c5NIkmfxeuiDJT07e80eT3/9rzpoIR0menWTvGOOWMcb3krw/yflzrmndGGPcMca4cfL821n4xXNSFo7h5ZPNLk/ykvlUuP5U1Y4kP5/knZNxJXlBkisnmzieh6mqjk3y00nelSRjjO+NMe6N83O5tib5oaramuTRSe6Ic/OwjTH+Osk9S6YPdS6en+SPx4JrkxxXVU9YnUrXh4MdzzHGX44xHpwMr02yY/L8/CTvH2PcP8b4apK9Wfj9v+aslXB0UpLb2njfZI4jVFVPTPKMJNclOXGMccfkpTuTnDinstajtyR5TZJ/mowfm+Te9g/eOXr4Tklyd5L3TC5TvrOqHhPn5xEbY9ye5PeTfC0Loei+JDfEuTmtQ52LfjdN75eS/Pnk+bo5nmslHDEDVfXDSf4kya+PMb7VXxsL92xw34bDUFXnJblrjHHDvGvZILYmOT3JO8YYz0jynSy5hOb8PDyTXpjzsxA4tyd5TA68pMEUnIuzU1Wvy0Lbx/vmXcuRWivh6PYkJ7fxjskch6mqjspCMHrfGONDk+mvf38JePJ417zqW2eem+TFVfUPWbjE+4Is9MwcN7mUkThHj8S+JPvGGNdNxldmISw5P4/czyb56hjj7jHGA0k+lIXz1bk5nUOdi343LVNVvSLJeUl+cTx8Q8V1czzXSji6Psmpk7+4ODoLDVtXzbmmdWPSD/OuJDePMf6gvXRVkgsnzy9M8uHVrm09GmNcOsbYMcZ4YhbOxU+MMX4xyTVJXjrZzPE8TGOMO5PcVlU/MZk6O8lNcX4ux9eSnFlVj578u//+sXRuTudQ5+JVSf795K/WzkxyX7v8xiFU1blZaEt48Rjju+2lq5JcUFXbquqULDS6//08anwka+YO2VX1oiz0eWxJ8u4xxu/OuaR1o6qel+RvknwuD/fI/E4W+o4+mORHk9ya5GVjjKWNiPwAVfX8JP9pjHFeVf14FlaSTkjy6ST/doxx/zzrWy+q6rQsNLcfneSWJBdl4X/OnJ9HqKr+a5JfyMLlik8n+eUs9G04Nw9DVV2R5PlJHpfk60len+R/5yDn4iSAvj0Lly6/m+SiMcbuedS9Vh3ieF6aZFuSb0w2u3aM8SuT7V+XhT6kB7PQAvLnSz9zLVgz4QgAYC1YK5fVAADWBOEIAKARjgAAGuEIAKARjgAAGuEIAKARjgAAmv8PUkbwtX7wXDkAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["plot_confusion_matrix(SNIPS_second_cm_intent, label=\"Intents\")\n","plot_confusion_matrix(SNIPS_second_cm_slot, label=\"Slots\")"],"metadata":{"id":"BlWqWVhLl6f9","executionInfo":{"status":"ok","timestamp":1675095041173,"user_tz":-60,"elapsed":15,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}},"outputId":"cbff60fa-da04-4b8d-9869-b29fb86654d5","colab":{"base_uri":"https://localhost:8080/","height":1000}},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"A42GRrrlVIOp"},"source":["## Third model"]},{"cell_type":"markdown","source":["### Monodirectional"],"metadata":{"id":"0zGXYxDFpFgm"}},{"cell_type":"code","source":["plot_confusion_matrix(ATIS_third_monodirectional_cm_intent, label=\"Intents\")\n","plot_confusion_matrix(ATIS_third_monodirectional_cm_slot, label=\"Slots\")"],"metadata":{"id":"Cc4eHWOIpFgo","executionInfo":{"status":"aborted","timestamp":1675095032687,"user_tz":-60,"elapsed":30,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_confusion_matrix(SNIPS_third_monodirectional_cm_intent, label=\"Intents\")\n","plot_confusion_matrix(SNIPS_third_monodirectional_cm_slot, label=\"Slots\")"],"metadata":{"id":"xxzhDZZVpFgp","executionInfo":{"status":"aborted","timestamp":1675095032688,"user_tz":-60,"elapsed":29,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Bidirectional"],"metadata":{"id":"-HC89mxdpFgq"}},{"cell_type":"code","source":["plot_confusion_matrix(ATIS_third_bidirectional_cm_intent, label=\"Intents\")\n","plot_confusion_matrix(ATIS_third_bidirectional_cm_slot, label=\"Slots\")"],"metadata":{"id":"3aD0_HzIpFgr","executionInfo":{"status":"aborted","timestamp":1675095032689,"user_tz":-60,"elapsed":30,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_confusion_matrix(SNIPS_third_bidirectional_cm_intent, label=\"Intents\")\n","plot_confusion_matrix(SNIPS_third_bidirectional_cm_slot, label=\"Slots\")"],"metadata":{"id":"3-I1IhH2pFgs","executionInfo":{"status":"aborted","timestamp":1675095032690,"user_tz":-60,"elapsed":31,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rlKBy1GCW2l4","executionInfo":{"status":"aborted","timestamp":1675095032691,"user_tz":-60,"elapsed":31,"user":{"displayName":"pierluca faccin","userId":"11778685678543199943"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["aFvq0jAA-9Ho","H0JN6bwYjcSe","jRpFeQSAiWa9","EWeBWpJXi771","krbPlc38ptBf","Rl9mtV_Q-bK7"],"provenance":[{"file_id":"1esg9jaEGE-NOjaNTx-e8c2F-xh6yWL7t","timestamp":1675099681192}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}